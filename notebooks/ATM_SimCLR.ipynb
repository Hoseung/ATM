{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b92497-778f-4664-892f-4c906672f47c",
   "metadata": {},
   "source": [
    "Restart cuda module after suspend by:  \n",
    "`$ sudo rmmod nvidia_uvm`  \n",
    "`$ sudo modprobe nvidia_uvm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb13103f-c7c2-4535-af7d-6f6b75b66930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "import atm\n",
    "import atm.simclr as simclr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425938e-ef50-46b9-9fac-aee1b751f37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataSet\n",
    "\n",
    "### Q: How do I let a dataset yield a pair of images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224625a8-de37-4edb-aa21-b49794f18a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.data='./datasets' \n",
    "args.dataset_name='cifar10'\n",
    "args.arch='resnet50'\n",
    "args.workers=1\n",
    "args.epochs=300 \n",
    "args.batch_size=256 \n",
    "args.lr=0.06 \n",
    "args.wd=0.0005\n",
    "args.disable_cuda=False\n",
    "args.fp16_precision=True\n",
    "args.out_dim=128\n",
    "args.log_every_n_steps=100\n",
    "args.temperature=0.07\n",
    "args.n_views = 2\n",
    "args.gpu_index=0\n",
    "args.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "#args.bn_splits=8 \n",
    "#args.cos=True \n",
    "#args.knn_k=200 \n",
    "#args.knn_t=0.1 \n",
    "\n",
    "#args.resume='' \n",
    "#args.schedule=[] \n",
    "#args.symmetric=False \n",
    "\n",
    "print(\"Using device:\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a4a1036-3af8-4b40-9326-f560cdfad33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    args.gpu_index = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f12c6-9529-4f01-a739-3612934790f2",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25347804-be03-4c8d-8569-6d55f6a6794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torchvision.datasets import VisionDataset\n",
    "from functools import partial\n",
    "from astrobf.tmo import Mantiuk_Seidel\n",
    "\n",
    "class TonemapImageDataset(VisionDataset):\n",
    "    def __init__(self, \n",
    "                 data_array, \n",
    "                 tmo,\n",
    "                 labels: Optional = None, \n",
    "                 train: bool=True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,):\n",
    "        self._array = data_array\n",
    "        self._good_gids = np.array([gal['img_name'] for gal in data_array])\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.tmo = tmo\n",
    "        self._bad_tmo=False\n",
    "\n",
    "    def _apply_tm(self, image):\n",
    "        try:\n",
    "            return self.tmo(image)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"division by zero. Probably bad choice of TM parameters\")\n",
    "            self._bad_tmo=True\n",
    "            return image\n",
    "\n",
    "    def _to_8bit(self, image):\n",
    "        \"\"\"\n",
    "        Normalize per image (or use global min max??)\n",
    "        \"\"\"\n",
    "\n",
    "        image = (image - image.min())/image.ptp()\n",
    "        image *= 255\n",
    "        return image.astype('uint8')        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._array)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        For super\n",
    "        \"\"\"\n",
    "        image, _segmap, weight = self._array[idx]['data']\n",
    "        image[_segmap.astype(bool)] = np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "\n",
    "        image = self._to_8bit(self._apply_tm(image))\n",
    "        \n",
    "        label = self.img_labels[idx]\n",
    "        return Image.fromarray(image), label\n",
    "    \n",
    "    \n",
    "class TonemapImageDatasetPair(TonemapImageDataset):\n",
    "    \"\"\"\n",
    "    returns two differently (randomly) transformed version of an image.\n",
    "    \n",
    "    img_labels = np.ndarray\n",
    "    \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        image, _segmap, weight = self._array[idx]['data']\n",
    "        image[_segmap.astype(bool)] = np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "        \n",
    "        image = self._to_8bit(self._apply_tm(image))\n",
    "        image = Image.fromarray(image)\n",
    "        label = self.img_labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(image) # random transform. \n",
    "            im_2 = self.transform(image)\n",
    "\n",
    "        return (im_1, im_2), label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cab40c1-0d38-49b5-8a0e-1a7055428655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ddir = \"../../bf_data/Nair_and_Abraham_2010/\"\n",
    "\n",
    "fn = ddir + \"all_gals.pickle\"\n",
    "all_gals = pickle.load(open(fn, \"rb\"))\n",
    "\n",
    "all_gals = all_gals[1:] # Why the first galaxy image is NaN?\n",
    "\n",
    "good_gids = np.array([gal['img_name'] for gal in all_gals])\n",
    "\n",
    "from astrobf.utils.misc import load_Nair\n",
    "cat_data = load_Nair(ddir + \"catalog/table2.dat\")\n",
    "# pd dataframe\n",
    "\n",
    "cat = cat_data[cat_data['ID'].isin(good_gids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba07c63-5f49-436d-8cae-d2188f280259",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmo_params = {'b': 6.0,  'c': 3.96, 'dl': 9.22, 'dh': 2.45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a4a7f5c-8849-41be-907a-e88ebe3e2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8), \n",
    "    #transforms.RandomGrayscale(p=0.2), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.2])])#[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]) \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.2])])#0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])\n",
    "\n",
    "# data prepare\n",
    "train_data = TonemapImageDatasetPair(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                     labels=cat['TT'].to_numpy(),\n",
    "                                     train=True, \n",
    "                                     transform=train_transform)\n",
    "train_loader = DataLoader(train_data, batch_size=args.batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "#test_data = TonemapImageDataset(all_gals, train=False, transform=test_transform)\n",
    "#test_loader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362b2b8-c679-4306-ba72-84a89a922074",
   "metadata": {},
   "source": [
    "## quick check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "507366ef-bc71-48df-ac15-055d062cbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simclr.models.ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde1016-902b-4114-969e-18c7842acbc5",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2163f500-cb54-4f08-b483-6f67a2769094",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.wd)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                           last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10e0a092-d172-44de-9257-57de8460bc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'atm.simclr.models' from '/home/hoseung/Work/ATM/atm/simclr/models.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(simclr)\n",
    "importlib.reload(simclr.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d14f370b-0c79-4ef4-a3af-e7037422167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:03<00:00, 11.15it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.35it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.39it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.43it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.42it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.45it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.35it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.29it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.43it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.40it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.32it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.44it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.41it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.32it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.38it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.37it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.29it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.27it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.79it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.84it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.81it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.79it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.45it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.36it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.89it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.82it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.79it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.71it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.87it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.82it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.82it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.81it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.71it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.71it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.40it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.09it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.40it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.30it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.36it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.28it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.44it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.44it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.26it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.23it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.26it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.35it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n"
     ]
    }
   ],
   "source": [
    "np.seterr(divide='ignore')\n",
    "\n",
    "with torch.cuda.device(args.gpu_index):\n",
    "    simc = simclr.models.SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simc.train(train_loader) # model is saved at the end of train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82e68d-51f4-4d78-ac0e-09204e412556",
   "metadata": {},
   "source": [
    "Training이 잘 되었는지 어떻게 알 것인가? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f2dd1-83f3-4f86-95c9-66a67b46d59b",
   "metadata": {},
   "source": [
    "# representation quality check\n",
    "\n",
    "## linear evaluation protocol, a standard way\n",
    "Train a linear classifier on the fixed representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd287d-2ce8-49be-a900-1efe37dc13e0",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4789dc5-ca42-4c5f-91d6-4871d76833ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('./runs/Aug09_01-49-10_hoseung/checkpoint_0030.pth.tar', map_location=args.device)\n",
    "state_dict = checkpoint['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66819adb-87b1-4fe5-b04e-29a18229a06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "#sclr = simclr.models.SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "#resnet = sclr.model\n",
    "resnet = simclr.models.ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "log = resnet.load_state_dict(state_dict, strict=False)\n",
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b44696-26ce-4c84-acee-e6f5a37bea7f",
   "metadata": {},
   "source": [
    "### Discard the projection head and leave the original backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcfe77ee-dcac-4a9c-8758-60b3c4168776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the projectio head\n",
    "resnet.backbone.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "58f72538-0511-44be-a23b-07ae38c733f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=3e-4, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8b100bbc-4cc5-46bd-b87f-fecd9f177571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = torchvision.datasets.CIFAR10('./data', train=True, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10('./data', train=False, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
    "# num_workers=0. Using multiple (even num_workers=1) causes an error 'can only test a child process'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "995934b9-9aac-4611-920a-38ddfd4dddbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-d3c238119daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    top1_train_accuracy = 0\n",
    "    for counter, (x_batch,y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        y_batch = y_batch.to(args.device)\n",
    "        \n",
    "        logits = resnet(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "        top1_train_accuracy += top1[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    top1_train_accuracy /= (counter + 1)\n",
    "    top1_accuracy = 0\n",
    "    top5_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        y_batch = y_batch.to(args.device)\n",
    "\n",
    "        logits = resnet(x_batch)\n",
    "\n",
    "        top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "        top1_accuracy += top1[0]\n",
    "        top5_accuracy += top5[0]\n",
    "\n",
    "    top1_accuracy /= (counter + 1)\n",
    "    top5_accuracy /= (counter + 1)\n",
    "    print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c547670-5db7-444a-bf75-a9ab1c28a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f0fd7-cd2a-48ea-a509-2d91c60f1e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a883-dc56-439c-a5d5-dd4cec870c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimCLRClassifier(nn.Module):\n",
    "    def __init__(self, base_model, freeze_base, base_feature_size=512, n_views=2):\n",
    "        self.embeddings = base_model\n",
    "        \n",
    "        if freeze_base:\n",
    "            print(\"Freezing embeddings\")\n",
    "            for param in self.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.classifier = nn.Linear(in_features = base_feature_size, \n",
    "                                   out_features = n_views) #\n",
    "    \n",
    "    def forward(self, X, *args):\n",
    "        emb = self.embeddings(X)\n",
    "        return self.classifier(emb)\n",
    "    \n",
    "class SimCLRClassifierModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b98fb7d-5412-4a0b-99da-e178b5fc7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44972a0b-3eb2-497b-a23c-654373fc8ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader, module):\n",
    "    with torch.no_grad():\n",
    "        progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "        module.eval().cuda()\n",
    "        true_y, pred_y = [], []\n",
    "        for i, batch_ in enumerate(data_loader):\n",
    "            X, y = batch_\n",
    "            print(progress[i % len(progress)], end=\"\\r\")\n",
    "            y_pred = torch.argmax(module(X.cuda()), dim=1)\n",
    "            true_y.extend(y.cpu())\n",
    "            pred_y.extend(y_pred.cpu())\n",
    "        print(classification_report(true_y, pred_y, digits=3))\n",
    "        return true_y, pred_y\n",
    "\n",
    "_ = evaluate(module.val_dataloader(), module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
