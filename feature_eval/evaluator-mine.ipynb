{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Hoseung/ATM/blob/main/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YUemQib7ZE4D"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lDfbL3w_Z0Od",
    "outputId": "41ae47c0-987d-4803-ec93-9b9f478b001e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_id_by_model(folder_name):\n",
    "  file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n",
    "             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n",
    "             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n",
    "  return file_id.get(folder_name, \"Model not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18_100-epochs_stl10 14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'resnet18_100-epochs_stl10'\n",
    "file_id = get_file_id_by_model(folder_name)\n",
    "print(folder_name, file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BfIPl0G6_RrT"
   },
   "outputs": [],
   "source": [
    "def get_stl10_data_loaders(download, n_channel=3, batch_size=256):\n",
    "    _transform = [transforms.ToTensor()]\n",
    "    if n_channel == 1:\n",
    "        _transform = _transform + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "    train_dataset = datasets.STL10('./data', split='train', download=download,\n",
    "                                  transform=transforms.Compose(_transform))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=True)\n",
    "\n",
    "    test_dataset = datasets.STL10('./data', split='test', download=download,\n",
    "                                  transform=transforms.Compose(_transform))\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def get_cifar10_data_loaders(download, n_channel=3, shuffle=False, batch_size=256):\n",
    "    _transform = [transforms.ToTensor()]\n",
    "    if n_channel == 1:\n",
    "        _transform = _transform + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "    train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
    "                                  transform=transforms.Compose(_transform))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=True)\n",
    "\n",
    "    test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
    "                                  transform=transforms.Compose(_transform))\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2*batch_size, # why *2?\n",
    "                            num_workers=10, drop_last=False, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6N8lYkbmDTaK"
   },
   "outputs": [],
   "source": [
    "dataset_name = ['galaxy', 'cifar10', 'stl10'][0]\n",
    "if dataset_name == 'galaxy':\n",
    "    tmo_params = {'b': 6.0,  'c': 3.96, 'dl': 9.22, 'dh': 2.45}\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    ddir = \"../../tonemap/bf_data/Nair_and_Abraham_2010/\"\n",
    "\n",
    "    fn = ddir + \"all_gals.pickle\"\n",
    "    all_gals = pickle.load(open(fn, \"rb\"))\n",
    "    all_gals = all_gals[1:] # Why the first galaxy image is NaN?\n",
    "    good_gids = np.array([gal['img_name'] for gal in all_gals])\n",
    "\n",
    "    from astrobf.utils.misc import load_Nair\n",
    "    cat_data = load_Nair(ddir + \"catalog/table2.dat\")\n",
    "    # pd dataframe\n",
    "\n",
    "    cat = cat_data[cat_data['ID'].isin(good_gids)]\n",
    "    labels = np.digitize(cat['TT'], np.sort(cat['TT'].unique()), right=True)\n",
    "    \n",
    "    n_classes = cat['TT'].nunique()\n",
    "else:\n",
    "    n_classes = 10\n",
    "    \n",
    "arch = 'resnet50'\n",
    "batch_size = 32\n",
    "n_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "a18lPD-tIle6"
   },
   "outputs": [],
   "source": [
    "import atm\n",
    "import atm.simclr as simclr\n",
    "import atm.simclr.resnet as models\n",
    "\n",
    "if arch == 'resnet18':\n",
    "    #model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
    "    model = models.resnet18(pretrained=False, num_classes=n_classes, num_channels=n_channels).to(device)\n",
    "elif arch == 'resnet50':\n",
    "    #model = torchvision.models.resnet50(pretrained=False, num_classes=n_classes).to(device)\n",
    "    model = models.resnet50(pretrained=False, num_classes=n_classes, num_channels=n_channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4AIfgq41GuTT"
   },
   "outputs": [],
   "source": [
    "bare = False\n",
    "\n",
    "if bare:\n",
    "    # Bare R18_ch1\n",
    "    fn_pth = '/home/hoseung/Dropbox/temp/runs/20210930-025624_cifar10_resnet18_1_256/Resnet_ch1_cifar10_bn256_200_199.pth'\n",
    "else:\n",
    "    # SimCLR_R50_ch1 \n",
    "    fn_pth = '/home/hoseung/Dropbox/temp/runs/20210929-192413_cifar10_resnet50_1_256/checkpoint_0200.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4AIfgq41GuTT"
   },
   "outputs": [],
   "source": [
    "#fn_pth = 'checkpoint_0100.pth.tar'\n",
    "fn_pth = '/home/hoseung/Dropbox/temp/Sep29_04-42-49_lambda/checkpoint_0300.pth.tar' # Resnet50\n",
    "checkpoint = torch.load(fn_pth, map_location=device)\n",
    "state_dict = checkpoint['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4AIfgq41GuTT"
   },
   "outputs": [],
   "source": [
    "target_word = ['module.backbone', 'backbone'][0]\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(target_word+'.'):\n",
    "        if k.startswith(target_word) and not k.startswith(target_word+'.fc'):\n",
    "          # remove prefix\n",
    "          state_dict[k[len(target_word+'.'):]] = state_dict[k]\n",
    "    del state_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VVjA83PPJYWl"
   },
   "outputs": [],
   "source": [
    "log = model.load_state_dict(state_dict, strict=False)\n",
    "assert log.missing_keys == ['fc.weight', 'fc.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "18ea8973ca674791adbc2f5262316199",
      "961733e919184ebdab42a4b16ed8ac39",
      "39439aab9398436fb4578c90f68ee1c2",
      "121a82b7474c4040bb1f79d8e84e025e",
      "ee43f26ffcd74c6d81e5bb2f91246f8f",
      "ff1db819936e4e828c8a24f9e4a6118a",
      "dd2224e928b542f8b0ef81dcac132e4c",
      "58816800e98f4b3fa0cd2746f433e1f5",
      "3ad1a3a36ed647d68f76544050800a99",
      "272966e271b5460090919a65785b3e9f",
      "31f22d7007cd49c9b49ef8969e17112d"
     ]
    },
    "id": "_GC0a14uWRr6",
    "outputId": "db93d340-f5df-4c41-ff03-aee3827a2cf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: galaxy\n"
     ]
    }
   ],
   "source": [
    "from atm.loader import TonemapImageDataset\n",
    "from functools import partial\n",
    "from astrobf.tmo import Mantiuk_Seidel\n",
    "\n",
    "def get_simclr_pipeline_transform(size, s=1, n_channels=3):\n",
    "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "    if n_channels == 3:\n",
    "        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                                          transforms.ToTensor()])\n",
    "    elif n_channels == 1:\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "#                                          transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True)),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "    return data_transforms\n",
    "\n",
    "if dataset_name == 'cifar10':\n",
    "    train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
    "elif dataset_name == 'stl10':\n",
    "    train_loader, test_loader = get_stl10_data_loaders(download=True)\n",
    "elif dataset_name == \"galaxy\":\n",
    "    train_dataset = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                        labels=labels,\n",
    "                                        train=True, \n",
    "                                        transform=transforms.Compose([transforms.RandomResizedCrop(size=128),\n",
    "                                                                      transforms.ToTensor()]),\n",
    "                                        #get_simclr_pipeline_transform(128, n_channels=n_channels)\n",
    "                                        )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        pin_memory=True, drop_last=True)\n",
    "    \n",
    "    test_dataset = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                        labels=cat['TT'].to_numpy(),\n",
    "                                        train=False, \n",
    "                                        transform=transforms.Compose([transforms.RandomResizedCrop(size=128),\n",
    "                                                                      transforms.ToTensor()]),\n",
    "                                       #get_simclr_pipeline_transform(128, n_channels=n_channels)\n",
    "                                        )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=2*batch_size, shuffle=True, # why 2*??\n",
    "        pin_memory=True, drop_last=True)\n",
    "    \n",
    "print(\"Dataset:\", dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pYT_KsM0Mnnr"
   },
   "outputs": [],
   "source": [
    "# freeze all layers but the last fc\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False\n",
    "\n",
    "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "assert len(parameters) == 2  # fc.weight, fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "aPVh1S_eMRDU"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "edr6RhP2PdVq"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210930-122043_galaxy_resnet50_1_transfer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTop1 Train accuracy 27.086828231811523\tTop1 Test accuracy: 4.414848804473877\tTop5 test acc: 30.494966506958008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b7c9c243f377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    393\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 395\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    396\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = timestr + f\"_{dataset_name}_{arch}_{n_channels}_transfer\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "print(writer.log_dir)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    top1_train_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "\n",
    "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "        top1_train_accuracy += top1[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    top1_train_accuracy /= (counter + 1)\n",
    "    top1_accuracy = 0\n",
    "    top5_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        logits = model(x_batch)\n",
    "\n",
    "        top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "        top1_accuracy += top1[0]\n",
    "        top5_accuracy += top5[0]\n",
    "\n",
    "    top1_accuracy /= (counter + 1)\n",
    "    top5_accuracy /= (counter + 1)\n",
    "\n",
    "    # write everystep\n",
    "    writer.add_scalar('loss', loss, global_step=epoch)\n",
    "    writer.add_scalar('acc/top1', top1_accuracy, global_step=epoch)\n",
    "    writer.add_scalar('acc/top5', top5_accuracy, global_step=epoch)\n",
    "    #writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "    print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\"\n",
    "            f\"\\tTop1 Test accuracy: {top1_accuracy.item()}\"\n",
    "            f\"\\tTop5 test acc: {top5_accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the output dimension of the model meets the number of possible labels, which is NOT 10 for Nair dataset. Mismatch will cause the error as follows:  \n",
    "\n",
    "\n",
    "`loss.backward()  `  \n",
    "`...  `  \n",
    "`RuntimeError: cuda runtime error (710) : device-side assert triggered at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:235`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# '20210930-044403_stl10_resnet18_3_transfer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOder0dAMI7X",
    "outputId": "d0e991cf-8c38-450c-d6b8-28cf11d40572",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\tTop1 Train accuracy 35.14229965209961\tTop1 Test accuracy: 42.522403717041016\tTop5 test acc: 88.72932434082031\n",
      "Epoch 1\tTop1 Train accuracy 43.14293670654297\tTop1 Test accuracy: 44.34397888183594\tTop5 test acc: 89.89545440673828\n",
      "Epoch 2\tTop1 Train accuracy 45.027503967285156\tTop1 Test accuracy: 45.86511993408203\tTop5 test acc: 90.63419342041016\n",
      "Epoch 3\tTop1 Train accuracy 46.600364685058594\tTop1 Test accuracy: 46.72966384887695\tTop5 test acc: 91.29595184326172\n",
      "Epoch 4\tTop1 Train accuracy 47.303890228271484\tTop1 Test accuracy: 47.55974197387695\tTop5 test acc: 91.66475677490234\n",
      "Epoch 5\tTop1 Train accuracy 48.06959533691406\tTop1 Test accuracy: 48.08249282836914\tTop5 test acc: 91.78308868408203\n",
      "Epoch 6\tTop1 Train accuracy 48.61606979370117\tTop1 Test accuracy: 48.09455490112305\tTop5 test acc: 91.86235809326172\n",
      "Epoch 7\tTop1 Train accuracy 49.043365478515625\tTop1 Test accuracy: 48.32892990112305\tTop5 test acc: 92.18462371826172\n",
      "Epoch 8\tTop1 Train accuracy 49.37818908691406\tTop1 Test accuracy: 48.79538345336914\tTop5 test acc: 92.23977661132812\n",
      "Epoch 9\tTop1 Train accuracy 49.86686706542969\tTop1 Test accuracy: 48.864891052246094\tTop5 test acc: 92.39832305908203\n",
      "Epoch 10\tTop1 Train accuracy 50.08370590209961\tTop1 Test accuracy: 49.10788345336914\tTop5 test acc: 92.48506927490234\n",
      "Epoch 11\tTop1 Train accuracy 50.27582931518555\tTop1 Test accuracy: 49.183712005615234\tTop5 test acc: 92.57295989990234\n",
      "Epoch 12\tTop1 Train accuracy 50.36112594604492\tTop1 Test accuracy: 49.574337005615234\tTop5 test acc: 92.69991302490234\n",
      "Epoch 13\tTop1 Train accuracy 50.50542068481445\tTop1 Test accuracy: 49.612247467041016\tTop5 test acc: 92.60340118408203\n",
      "Epoch 14\tTop1 Train accuracy 50.62818908691406\tTop1 Test accuracy: 49.81100845336914\tTop5 test acc: 92.59477996826172\n",
      "Epoch 15\tTop1 Train accuracy 51.05867385864258\tTop1 Test accuracy: 49.900047302246094\tTop5 test acc: 92.7073745727539\n",
      "Epoch 16\tTop1 Train accuracy 51.158321380615234\tTop1 Test accuracy: 50.120059967041016\tTop5 test acc: 92.81824493408203\n",
      "Epoch 17\tTop1 Train accuracy 51.33808898925781\tTop1 Test accuracy: 50.129825592041016\tTop5 test acc: 92.77803802490234\n",
      "Epoch 18\tTop1 Train accuracy 51.472415924072266\tTop1 Test accuracy: 50.22116470336914\tTop5 test acc: 92.8440933227539\n",
      "Epoch 19\tTop1 Train accuracy 51.342472076416016\tTop1 Test accuracy: 50.251609802246094\tTop5 test acc: 92.98311614990234\n",
      "Epoch 20\tTop1 Train accuracy 51.44889831542969\tTop1 Test accuracy: 50.188419342041016\tTop5 test acc: 93.04055786132812\n",
      "Epoch 21\tTop1 Train accuracy 51.71675491333008\tTop1 Test accuracy: 50.49000549316406\tTop5 test acc: 93.03194427490234\n",
      "Epoch 22\tTop1 Train accuracy 51.776546478271484\tTop1 Test accuracy: 50.41532516479492\tTop5 test acc: 93.0101089477539\n",
      "Epoch 23\tTop1 Train accuracy 51.62826919555664\tTop1 Test accuracy: 50.41188049316406\tTop5 test acc: 93.06124114990234\n",
      "Epoch 24\tTop1 Train accuracy 51.797271728515625\tTop1 Test accuracy: 50.443477630615234\tTop5 test acc: 93.1761245727539\n",
      "Epoch 25\tTop1 Train accuracy 52.14445114135742\tTop1 Test accuracy: 50.57157516479492\tTop5 test acc: 93.10030364990234\n",
      "Epoch 26\tTop1 Train accuracy 51.953521728515625\tTop1 Test accuracy: 50.823184967041016\tTop5 test acc: 93.21633911132812\n",
      "Epoch 27\tTop1 Train accuracy 52.13249206542969\tTop1 Test accuracy: 50.931758880615234\tTop5 test acc: 93.15027618408203\n",
      "Epoch 28\tTop1 Train accuracy 52.091835021972656\tTop1 Test accuracy: 50.647403717041016\tTop5 test acc: 93.14797973632812\n",
      "Epoch 29\tTop1 Train accuracy 52.30030059814453\tTop1 Test accuracy: 50.92601013183594\tTop5 test acc: 93.14797973632812\n",
      "Epoch 30\tTop1 Train accuracy 52.21938705444336\tTop1 Test accuracy: 50.80250549316406\tTop5 test acc: 93.14913177490234\n",
      "Epoch 31\tTop1 Train accuracy 52.336971282958984\tTop1 Test accuracy: 50.950138092041016\tTop5 test acc: 93.11006927490234\n",
      "Epoch 32\tTop1 Train accuracy 52.41310501098633\tTop1 Test accuracy: 50.97828674316406\tTop5 test acc: 93.27493286132812\n",
      "Epoch 33\tTop1 Train accuracy 52.370853424072266\tTop1 Test accuracy: 50.99781799316406\tTop5 test acc: 93.18819427490234\n",
      "Epoch 34\tTop1 Train accuracy 52.50836944580078\tTop1 Test accuracy: 51.13338851928711\tTop5 test acc: 93.13074493408203\n",
      "Epoch 35\tTop1 Train accuracy 52.59048080444336\tTop1 Test accuracy: 50.975990295410156\tTop5 test acc: 93.28469848632812\n",
      "Epoch 36\tTop1 Train accuracy 52.48604965209961\tTop1 Test accuracy: 51.184513092041016\tTop5 test acc: 93.19795989990234\n",
      "Epoch 37\tTop1 Train accuracy 52.609214782714844\tTop1 Test accuracy: 50.95875549316406\tTop5 test acc: 93.18819427490234\n",
      "Epoch 38\tTop1 Train accuracy 52.49003219604492\tTop1 Test accuracy: 50.99666976928711\tTop5 test acc: 93.31399536132812\n",
      "Epoch 39\tTop1 Train accuracy 52.798946380615234\tTop1 Test accuracy: 51.07594299316406\tTop5 test acc: 93.29676055908203\n",
      "Epoch 40\tTop1 Train accuracy 52.60483169555664\tTop1 Test accuracy: 51.174747467041016\tTop5 test acc: 93.27608489990234\n",
      "Epoch 41\tTop1 Train accuracy 52.616390228271484\tTop1 Test accuracy: 51.2321891784668\tTop5 test acc: 93.22725677490234\n",
      "Epoch 42\tTop1 Train accuracy 52.88304901123047\tTop1 Test accuracy: 51.3166389465332\tTop5 test acc: 93.29561614990234\n",
      "Epoch 43\tTop1 Train accuracy 53.003028869628906\tTop1 Test accuracy: 51.3005485534668\tTop5 test acc: 93.28585052490234\n",
      "Epoch 44\tTop1 Train accuracy 52.727596282958984\tTop1 Test accuracy: 51.3459358215332\tTop5 test acc: 93.32720184326172\n",
      "Epoch 45\tTop1 Train accuracy 52.73397445678711\tTop1 Test accuracy: 51.386146545410156\tTop5 test acc: 93.25655364990234\n",
      "Epoch 46\tTop1 Train accuracy 52.844783782958984\tTop1 Test accuracy: 51.2224235534668\tTop5 test acc: 93.36282348632812\n",
      "Epoch 47\tTop1 Train accuracy 52.852359771728516\tTop1 Test accuracy: 51.3591423034668\tTop5 test acc: 93.33467864990234\n",
      "Epoch 48\tTop1 Train accuracy 52.95320510864258\tTop1 Test accuracy: 51.395912170410156\tTop5 test acc: 93.19048309326172\n",
      "Epoch 49\tTop1 Train accuracy 52.80332946777344\tTop1 Test accuracy: 51.249427795410156\tTop5 test acc: 93.33352661132812\n",
      "Epoch 50\tTop1 Train accuracy 52.91135025024414\tTop1 Test accuracy: 51.239662170410156\tTop5 test acc: 93.30538177490234\n",
      "Epoch 51\tTop1 Train accuracy 53.100284576416016\tTop1 Test accuracy: 51.36316680908203\tTop5 test acc: 93.30422973632812\n",
      "Epoch 52\tTop1 Train accuracy 52.896602630615234\tTop1 Test accuracy: 51.549861907958984\tTop5 test acc: 93.47024536132812\n",
      "Epoch 53\tTop1 Train accuracy 52.97951126098633\tTop1 Test accuracy: 51.317787170410156\tTop5 test acc: 93.41280364990234\n",
      "Epoch 54\tTop1 Train accuracy 52.98668670654297\tTop1 Test accuracy: 51.3459358215332\tTop5 test acc: 93.37258911132812\n",
      "Epoch 55\tTop1 Train accuracy 53.03252410888672\tTop1 Test accuracy: 51.34363555908203\tTop5 test acc: 93.41394805908203\n",
      "Epoch 56\tTop1 Train accuracy 53.10347366333008\tTop1 Test accuracy: 51.3459358215332\tTop5 test acc: 93.42256927490234\n",
      "Epoch 57\tTop1 Train accuracy 53.0169792175293\tTop1 Test accuracy: 51.3591423034668\tTop5 test acc: 93.41280364990234\n",
      "Epoch 58\tTop1 Train accuracy 53.117027282714844\tTop1 Test accuracy: 51.513099670410156\tTop5 test acc: 93.45186614990234\n",
      "Epoch 59\tTop1 Train accuracy 53.269691467285156\tTop1 Test accuracy: 51.3459358215332\tTop5 test acc: 93.48001098632812\n",
      "Epoch 60\tTop1 Train accuracy 53.124202728271484\tTop1 Test accuracy: 51.364315032958984\tTop5 test acc: 93.40418243408203\n",
      "Epoch 61\tTop1 Train accuracy 53.02176284790039\tTop1 Test accuracy: 51.44129180908203\tTop5 test acc: 93.31629180908203\n",
      "Epoch 62\tTop1 Train accuracy 53.117027282714844\tTop1 Test accuracy: 51.44129180908203\tTop5 test acc: 93.36742401123047\n",
      "Epoch 63\tTop1 Train accuracy 53.351402282714844\tTop1 Test accuracy: 51.549861907958984\tTop5 test acc: 93.37602996826172\n",
      "Epoch 64\tTop1 Train accuracy 53.12181091308594\tTop1 Test accuracy: 51.5021858215332\tTop5 test acc: 93.48116302490234\n",
      "Epoch 65\tTop1 Train accuracy 53.046077728271484\tTop1 Test accuracy: 51.6584358215332\tTop5 test acc: 93.39441680908203\n",
      "Epoch 66\tTop1 Train accuracy 53.33625411987305\tTop1 Test accuracy: 51.325252532958984\tTop5 test acc: 93.28813934326172\n",
      "Epoch 67\tTop1 Train accuracy 53.18159866333008\tTop1 Test accuracy: 51.315486907958984\tTop5 test acc: 93.43462371826172\n",
      "Epoch 68\tTop1 Train accuracy 53.22943115234375\tTop1 Test accuracy: 51.3459358215332\tTop5 test acc: 93.46277618408203\n",
      "Epoch 69\tTop1 Train accuracy 53.31034469604492\tTop1 Test accuracy: 51.452205657958984\tTop5 test acc: 93.34673309326172\n",
      "Epoch 70\tTop1 Train accuracy 53.17522048950195\tTop1 Test accuracy: 51.692901611328125\tTop5 test acc: 93.46277618408203\n",
      "Epoch 71\tTop1 Train accuracy 53.449058532714844\tTop1 Test accuracy: 51.540096282958984\tTop5 test acc: 93.43578338623047\n",
      "Epoch 72\tTop1 Train accuracy 53.308753967285156\tTop1 Test accuracy: 51.02366638183594\tTop5 test acc: 93.40532684326172\n",
      "Epoch 73\tTop1 Train accuracy 53.26729965209961\tTop1 Test accuracy: 51.73426055908203\tTop5 test acc: 93.43347930908203\n",
      "Epoch 74\tTop1 Train accuracy 53.335060119628906\tTop1 Test accuracy: 51.327552795410156\tTop5 test acc: 93.36742401123047\n",
      "Epoch 75\tTop1 Train accuracy 53.34383010864258\tTop1 Test accuracy: 51.57801055908203\tTop5 test acc: 93.41509246826172\n",
      "Epoch 76\tTop1 Train accuracy 53.25215148925781\tTop1 Test accuracy: 51.520565032958984\tTop5 test acc: 93.33812713623047\n",
      "Epoch 77\tTop1 Train accuracy 53.24537658691406\tTop1 Test accuracy: 51.546417236328125\tTop5 test acc: 93.48345184326172\n",
      "Epoch 78\tTop1 Train accuracy 53.42474365234375\tTop1 Test accuracy: 51.40222930908203\tTop5 test acc: 93.42485809326172\n",
      "Epoch 79\tTop1 Train accuracy 53.280452728271484\tTop1 Test accuracy: 51.54756546020508\tTop5 test acc: 93.38465118408203\n",
      "Epoch 80\tTop1 Train accuracy 53.21149444580078\tTop1 Test accuracy: 51.722198486328125\tTop5 test acc: 93.49207305908203\n",
      "Epoch 81\tTop1 Train accuracy 53.4315185546875\tTop1 Test accuracy: 51.63660430908203\tTop5 test acc: 93.50183868408203\n",
      "Epoch 82\tTop1 Train accuracy 53.24497604370117\tTop1 Test accuracy: 51.47058868408203\tTop5 test acc: 93.48230743408203\n",
      "Epoch 83\tTop1 Train accuracy 53.31193923950195\tTop1 Test accuracy: 51.51826858520508\tTop5 test acc: 93.39556121826172\n",
      "Epoch 84\tTop1 Train accuracy 53.424346923828125\tTop1 Test accuracy: 51.61707305908203\tTop5 test acc: 93.49321746826172\n",
      "Epoch 85\tTop1 Train accuracy 53.51681900024414\tTop1 Test accuracy: 51.61707305908203\tTop5 test acc: 93.37718963623047\n",
      "Epoch 86\tTop1 Train accuracy 53.3729248046875\tTop1 Test accuracy: 51.50965118408203\tTop5 test acc: 93.37718963623047\n",
      "Epoch 87\tTop1 Train accuracy 53.31792068481445\tTop1 Test accuracy: 51.71875\tTop5 test acc: 93.40532684326172\n",
      "Epoch 88\tTop1 Train accuracy 53.47935104370117\tTop1 Test accuracy: 51.4728889465332\tTop5 test acc: 93.40532684326172\n",
      "Epoch 89\tTop1 Train accuracy 53.322303771972656\tTop1 Test accuracy: 51.481502532958984\tTop5 test acc: 93.44324493408203\n",
      "Epoch 90\tTop1 Train accuracy 53.33585739135742\tTop1 Test accuracy: 51.5412483215332\tTop5 test acc: 93.48345184326172\n",
      "Epoch 91\tTop1 Train accuracy 53.370933532714844\tTop1 Test accuracy: 51.52918243408203\tTop5 test acc: 93.37602996826172\n",
      "Epoch 92\tTop1 Train accuracy 53.30078125\tTop1 Test accuracy: 51.68428421020508\tTop5 test acc: 93.51274871826172\n",
      "Epoch 93\tTop1 Train accuracy 53.42514419555664\tTop1 Test accuracy: 51.59639358520508\tTop5 test acc: 93.48230743408203\n",
      "Epoch 94\tTop1 Train accuracy 53.385284423828125\tTop1 Test accuracy: 51.57801055908203\tTop5 test acc: 93.43347930908203\n",
      "Epoch 95\tTop1 Train accuracy 53.53196716308594\tTop1 Test accuracy: 51.61592483520508\tTop5 test acc: 93.46392059326172\n",
      "Epoch 96\tTop1 Train accuracy 53.240989685058594\tTop1 Test accuracy: 51.57801055908203\tTop5 test acc: 93.45415496826172\n",
      "Epoch 97\tTop1 Train accuracy 53.47337341308594\tTop1 Test accuracy: 51.52803421020508\tTop5 test acc: 93.43578338623047\n",
      "Epoch 98\tTop1 Train accuracy 53.29320526123047\tTop1 Test accuracy: 51.595245361328125\tTop5 test acc: 93.37602996826172\n",
      "Epoch 99\tTop1 Train accuracy 53.40122604370117\tTop1 Test accuracy: 51.73311233520508\tTop5 test acc: 93.45301055908203\n"
     ]
    }
   ],
   "source": [
    "# ResNet이 내꺼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8032, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "id": "xiaMtv5_7cAI",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "121a82b7474c4040bb1f79d8e84e025e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ad1a3a36ed647d68f76544050800a99",
      "max": 2640397119,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_58816800e98f4b3fa0cd2746f433e1f5",
      "value": 2640397119
     }
    },
    "18ea8973ca674791adbc2f5262316199": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39439aab9398436fb4578c90f68ee1c2",
       "IPY_MODEL_121a82b7474c4040bb1f79d8e84e025e",
       "IPY_MODEL_ee43f26ffcd74c6d81e5bb2f91246f8f"
      ],
      "layout": "IPY_MODEL_961733e919184ebdab42a4b16ed8ac39"
     }
    },
    "272966e271b5460090919a65785b3e9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31f22d7007cd49c9b49ef8969e17112d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39439aab9398436fb4578c90f68ee1c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd2224e928b542f8b0ef81dcac132e4c",
      "placeholder": "​",
      "style": "IPY_MODEL_ff1db819936e4e828c8a24f9e4a6118a",
      "value": ""
     }
    },
    "3ad1a3a36ed647d68f76544050800a99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58816800e98f4b3fa0cd2746f433e1f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "961733e919184ebdab42a4b16ed8ac39": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd2224e928b542f8b0ef81dcac132e4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee43f26ffcd74c6d81e5bb2f91246f8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31f22d7007cd49c9b49ef8969e17112d",
      "placeholder": "​",
      "style": "IPY_MODEL_272966e271b5460090919a65785b3e9f",
      "value": " 2640397312/? [01:53&lt;00:00, 52488935.10it/s]"
     }
    },
    "ff1db819936e4e828c8a24f9e4a6118a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
