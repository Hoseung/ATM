{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b92497-778f-4664-892f-4c906672f47c",
   "metadata": {},
   "source": [
    "Restart cuda module after suspend by:  \n",
    "`$ sudo rmmod nvidia_uvm`  \n",
    "`$ sudo modprobe nvidia_uvm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29714ca-50dc-46b9-b5e9-8ce7d6e19049",
   "metadata": {},
   "source": [
    "1. Test용으로 몇 장 빼둘 것. \n",
    "2. Train의 목적: -- T-type을 N개의 label로 잘 구별하는 representation vector를 구하는 것.  \n",
    "3. 목적대로 train 되었는지 testset으로 확인 -- Freeze된 ResNet으로 classification을 잘 수행하는가..  \n",
    "    3.1 ResNet은 아무런 train이 필요 없나? 뭔갈 해야하나? \n",
    "4. train 잘 되었다면 그 담에 뭘 할까? -- M20, Gini, Contrast등의 값을 feature vector로 변경. --> custom_morph 코드를 Train된 ResNet으로 변경. \n",
    "\n",
    "ToneMapping이 바뀔 때마다 ResNet의 마지막 layer 정도는 fine-tune할 수 있지 않을까? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb13103f-c7c2-4535-af7d-6f6b75b66930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "import atm\n",
    "import atm.simclr as simclr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425938e-ef50-46b9-9fac-aee1b751f37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataSet\n",
    "\n",
    "Dataset yields a pair of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224625a8-de37-4edb-aa21-b49794f18a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.data='./datasets' \n",
    "args.dataset_name='cifar10'\n",
    "args.arch='resnet50'\n",
    "args.workers=1\n",
    "args.epochs=300 \n",
    "args.batch_size=256 \n",
    "args.lr=0.06 \n",
    "args.wd=0.0005\n",
    "args.disable_cuda=False\n",
    "args.fp16_precision=True\n",
    "args.out_dim=128\n",
    "args.log_every_n_steps=100\n",
    "args.temperature=0.07\n",
    "args.n_views = 2\n",
    "args.gpu_index=0\n",
    "args.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using device:\", args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a4a1036-3af8-4b40-9326-f560cdfad33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    args.gpu_index = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f12c6-9529-4f01-a739-3612934790f2",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25347804-be03-4c8d-8569-6d55f6a6794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from functools import partial\n",
    "from astrobf.tmo import Mantiuk_Seidel\n",
    "\n",
    "class TonemapImageDataset(VisionDataset):\n",
    "    def __init__(self, \n",
    "                 data_array, \n",
    "                 tmo,\n",
    "                 labels: Optional = None, \n",
    "                 train: bool=True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,):\n",
    "        self._array = data_array\n",
    "        self._good_gids = np.array([gal['img_name'] for gal in data_array])\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.tmo = tmo\n",
    "        self._bad_tmo=False\n",
    "\n",
    "    def _apply_tm(self, image):\n",
    "        try:\n",
    "            return self.tmo(image)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"division by zero. Probably bad choice of TM parameters\")\n",
    "            self._bad_tmo=True\n",
    "            return image\n",
    "\n",
    "    def _to_8bit(self, image):\n",
    "        \"\"\"\n",
    "        Normalize per image (or use global min max??)\n",
    "        \"\"\"\n",
    "\n",
    "        image = (image - image.min())/image.ptp()\n",
    "        image *= 255\n",
    "        return image.astype('uint8')        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._array)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        For super\n",
    "        \"\"\"\n",
    "        image, _segmap, weight = self._array[idx]['data']\n",
    "        image[_segmap.astype(bool)] = np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "\n",
    "        image = self._to_8bit(self._apply_tm(image))\n",
    "        \n",
    "        label = self.img_labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "class TonemapImageDatasetPair(TonemapImageDataset):\n",
    "    \"\"\"\n",
    "    returns two differently (randomly) transformed version of an image.\n",
    "    \n",
    "    img_labels = np.ndarray\n",
    "    \"\"\"\n",
    "    def __getitem__(self, idx):\n",
    "        image, _segmap, weight = self._array[idx]['data']\n",
    "        image[_segmap.astype(bool)] = np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "        \n",
    "        image = self._to_8bit(self._apply_tm(image))\n",
    "        image = Image.fromarray(image)\n",
    "        label = self.img_labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            im_1 = self.transform(image) # random transform. \n",
    "            im_2 = self.transform(image)\n",
    "\n",
    "        return (im_1, im_2), label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6421ccf-3c7b-4950-8043-c183bfa105b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ddir = \"../../tonemap/bf_data/Nair_and_Abraham_2010/\"\n",
    "\n",
    "fn = ddir + \"all_gals.pickle\"\n",
    "all_gals = pickle.load(open(fn, \"rb\"))\n",
    "\n",
    "all_gals = all_gals[1:] # Why the first galaxy image is NaN?\n",
    "\n",
    "good_gids = np.array([gal['img_name'] for gal in all_gals])\n",
    "\n",
    "from astrobf.utils.misc import load_Nair\n",
    "cat_data = load_Nair(ddir + \"catalog/table2.dat\")\n",
    "# pd dataframe\n",
    "\n",
    "cat = cat_data[cat_data['ID'].isin(good_gids)]\n",
    "\n",
    "tmo_params = {'b': 6.0,  'c': 3.96, 'dl': 9.22, 'dh': 2.45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b760c29-b5fd-4838-9603-fe29595c8649",
   "metadata": {},
   "source": [
    "EFIGI 은하에 대해서 테스트 하는건 어떰? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41810cb2-aa30-4cf9-b44c-138a9f709079",
   "metadata": {},
   "source": [
    "RandomCrop을 할 의미가 있을까?\n",
    "은하의 중심이 어느정도 결정되어있고, 일부를 봐야하는 상황은 없으며, radial한 pattern이 중요한데. \n",
    "거기다가 은하별로 크기가 많이 차이나서 잘못하면 텅텅 빈 공간을 잘라오는 수가 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ca18fb9-cb8e-4ef6-afc3-356d20c08cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(64),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8), \n",
    "    #transforms.RandomGrayscale(p=0.2), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.2])])#[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]) \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.2])])#0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4006a-2ced-4dcc-b1f9-f8190891faa7",
   "metadata": {},
   "source": [
    "## Split one chunk of dataset into train and test\n",
    "#### Use torch.utils.data.random_split or [torch.utils.data.SubsetRandomSampler](https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets/50544887#50544887)\n",
    "\n",
    "random_split takes a dataset -- for example, a tuple (tensor of data, tensor of label).  \n",
    "SubsetRandomSampler is sent to a DataLoader as an optional argument. SubsetRandomSampler better suits to my case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61f00707-b91b-4640-a5b2-9b41259bfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47a05272-3619-4d91-b1c5-48057ef83d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# data prepare\n",
    "frac_train = 0.9\n",
    "\n",
    "all_data = TonemapImageDatasetPair(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                     labels=cat['TT'].to_numpy(),\n",
    "                                     train=True, \n",
    "                                     transform=train_transform)\n",
    "\n",
    "all_data_val = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                     labels=cat['TT'].to_numpy(),\n",
    "                                     train=False, \n",
    "                                     transform=test_transform)\n",
    "len_data = len(all_data)\n",
    "\n",
    "data_idx = np.arange(len_data)\n",
    "np.random.shuffle(data_idx)\n",
    "ind = int(np.floor(len_data * frac_train))\n",
    "train_idx, test_idx = data_idx[:ind], data_idx[ind:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = DataLoader(all_data, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True, drop_last=True,\n",
    "                         sampler=train_sampler) # shuffle = False bc. sampler has randomized indices.\n",
    "\n",
    "test_loader = DataLoader(all_data_val, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True, drop_last=True,\n",
    "                         sampler=test_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b0ddf24-65c7-4c19-a2a8-1e580344ad07",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n"
     ]
    }
   ],
   "source": [
    "im, _ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02548d83-77d3-49dd-8075-83113564afc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa56b921100>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im[0][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d98aa605-5287-40b1-82db-9a1ec7699bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23ae50e5-e95d-44eb-8c1f-1ef18089992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 107, 107] at entry 0 and [1, 88, 88] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5816763a1304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 107, 107] at entry 0 and [1, 88, 88] at entry 1\n"
     ]
    }
   ],
   "source": [
    "im, _ = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08844d91-fed4-40de-861f-93793c00b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362b2b8-c679-4306-ba72-84a89a922074",
   "metadata": {},
   "source": [
    "## quick check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507366ef-bc71-48df-ac15-055d062cbdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simclr.models.ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde1016-902b-4114-969e-18c7842acbc5",
   "metadata": {},
   "source": [
    "# training\n",
    "\n",
    "## Goal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2163f500-cb54-4f08-b483-6f67a2769094",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.wd)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                           last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10e0a092-d172-44de-9257-57de8460bc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'atm.simclr.models' from '/home/hoseung/Work/ATM/atm/simclr/models.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(simclr)\n",
    "importlib.reload(simclr.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d14f370b-0c79-4ef4-a3af-e7037422167e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:03<00:00, 11.15it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.35it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.39it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.43it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.42it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.45it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.35it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.29it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.43it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.40it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.32it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.44it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.41it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.32it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.38it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.37it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.29it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.27it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.79it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.84it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.81it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.79it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.85it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.45it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.36it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.89it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.82it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.79it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.71it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.87it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.55it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.46it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.82it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.82it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.81it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.71it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.76it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.66it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.77it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.64it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.68it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.71it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.75it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.80it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.72it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.70it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.67it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.65it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.69it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.78it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.73it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.40it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.09it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.57it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.40it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.61it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.30it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.62it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.36it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.28it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.50it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.44it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.44it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.26it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.23it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.63it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.56it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.26it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.47it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.35it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.52it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.48it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.60it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.53it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.58it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.54it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.49it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.59it/s]\n",
      "100%|██████████| 37/37 [00:03<00:00, 11.51it/s]\n"
     ]
    }
   ],
   "source": [
    "np.seterr(divide='ignore')\n",
    "\n",
    "with torch.cuda.device(args.gpu_index):\n",
    "    simc = simclr.models.SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simc.train(train_loader) # model is saved at the end of train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82e68d-51f4-4d78-ac0e-09204e412556",
   "metadata": {},
   "source": [
    "Training이 잘 되었는지 어떻게 알 것인가? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f2dd1-83f3-4f86-95c9-66a67b46d59b",
   "metadata": {},
   "source": [
    "# representation quality check\n",
    "\n",
    "## linear evaluation protocol, a standard way\n",
    "Train a linear classifier on the fixed representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd287d-2ce8-49be-a900-1efe37dc13e0",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f863a7c-b316-40e3-a40a-f78bf9bbc1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./runs/Aug18_18-13-30_hoseung/checkpoint_0300.pth.tar', map_location=args.device)\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "#sclr = simclr.models.SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "#resnet = sclr.model\n",
    "resnet = simclr.models.ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "log = resnet.load_state_dict(state_dict, strict=False)\n",
    "print(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b44696-26ce-4c84-acee-e6f5a37bea7f",
   "metadata": {},
   "source": [
    "### Discard the projection head and leave the original backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcfe77ee-dcac-4a9c-8758-60b3c4168776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the projection head\n",
    "resnet.backbone.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa4249-c6fb-4ccc-a6b8-b2d95c805195",
   "metadata": {},
   "source": [
    "## t_SNE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eba302-b71b-4083-8692-cb92e51bd35d",
   "metadata": {},
   "source": [
    "### Get features of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6896d-91a1-4ec0-b09d-55063abb0ec6",
   "metadata": {},
   "source": [
    "test_transform에서 to_tensor해줬는데...??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46eb8e8-2b64-4990-ad9a-ad4086f6d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1020cfc7-aed3-4b7b-a5ef-b4cd8fd390f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-49a4f536d6a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab07201-3304-4332-b546-71971c577146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "132c0eb9-77db-4dbd-a666-02598fc24b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 122, 122] at entry 0 and [1, 134, 134] at entry 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-2216bc504db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in default_collate\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 83, in <listcomp>\n    return [default_collate(samples) for samples in transposed]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n    return torch.stack(batch, 0, out=out)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 122, 122] at entry 0 and [1, 134, 134] at entry 1\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "feature_arr = []\n",
    "for images, _ in tqdm(test_loader):\n",
    "    images = torch.cat(images[0], dim=0)\n",
    "    images = images.to(self.args.device)\n",
    "\n",
    "    # autocast <- AMP\n",
    "    with autocast(enabled=self.args.fp16_precision):\n",
    "        features = resnet(images)\n",
    "        \n",
    "    feature_arr.append(features.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bc6be-f43e-42bd-b6ba-6d8405e4ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D projection of 1024(?)-dim features\n",
    "tsne = TSNE(n_components=2).fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f72538-0511-44be-a23b-07ae38c733f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=3e-4, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3688320-95d0-4530-9912-b1fd240be9a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b100bbc-4cc5-46bd-b87f-fecd9f177571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = torchvision.datasets.CIFAR10('./data', train=True, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10('./data', train=False, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
    "# num_workers=0. Using multiple (even num_workers=1) causes an error 'can only test a child process'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7892c-858b-4537-9feb-e5d5a3edccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "995934b9-9aac-4611-920a-38ddfd4dddbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-d3c238119daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    top1_train_accuracy = 0\n",
    "    for counter, (x_batch,y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        y_batch = y_batch.to(args.device)\n",
    "        \n",
    "        logits = resnet(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "        top1_train_accuracy += top1[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    top1_train_accuracy /= (counter + 1)\n",
    "    top1_accuracy = 0\n",
    "    top5_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        y_batch = y_batch.to(args.device)\n",
    "\n",
    "        logits = resnet(x_batch)\n",
    "\n",
    "        top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "        top1_accuracy += top1[0]\n",
    "        top5_accuracy += top5[0]\n",
    "\n",
    "    top1_accuracy /= (counter + 1)\n",
    "    top5_accuracy /= (counter + 1)\n",
    "    print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c547670-5db7-444a-bf75-a9ab1c28a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f0fd7-cd2a-48ea-a509-2d91c60f1e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a883-dc56-439c-a5d5-dd4cec870c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimCLRClassifier(nn.Module):\n",
    "    def __init__(self, base_model, freeze_base, base_feature_size=512, n_views=2):\n",
    "        self.embeddings = base_model\n",
    "        \n",
    "        if freeze_base:\n",
    "            print(\"Freezing embeddings\")\n",
    "            for param in self.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.classifier = nn.Linear(in_features = base_feature_size, \n",
    "                                   out_features = n_views) #\n",
    "    \n",
    "    def forward(self, X, *args):\n",
    "        emb = self.embeddings(X)\n",
    "        return self.classifier(emb)\n",
    "    \n",
    "class SimCLRClassifierModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b98fb7d-5412-4a0b-99da-e178b5fc7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44972a0b-3eb2-497b-a23c-654373fc8ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader, module):\n",
    "    with torch.no_grad():\n",
    "        progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "        module.eval().cuda()\n",
    "        true_y, pred_y = [], []\n",
    "        for i, batch_ in enumerate(data_loader):\n",
    "            X, y = batch_\n",
    "            print(progress[i % len(progress)], end=\"\\r\")\n",
    "            y_pred = torch.argmax(module(X.cuda()), dim=1)\n",
    "            true_y.extend(y.cpu())\n",
    "            pred_y.extend(y_pred.cpu())\n",
    "        print(classification_report(true_y, pred_y, digits=3))\n",
    "        return true_y, pred_y\n",
    "\n",
    "_ = evaluate(module.val_dataloader(), module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
