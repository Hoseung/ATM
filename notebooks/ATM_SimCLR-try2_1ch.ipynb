{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86228d20-fcc0-4086-9c62-2675ef2db9f7",
   "metadata": {},
   "source": [
    "## SimCLR run.py expanded in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b92497-778f-4664-892f-4c906672f47c",
   "metadata": {},
   "source": [
    "Restart cuda module after suspend by:  \n",
    "`$ sudo rmmod nvidia_uvm`  \n",
    "`$ sudo modprobe nvidia_uvm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29714ca-50dc-46b9-b5e9-8ce7d6e19049",
   "metadata": {},
   "source": [
    "1. Test용으로 몇 장 빼둘 것. \n",
    "2. Train의 목적: -- T-type을 N개의 label로 잘 구별하는 representation vector를 구하는 것.  \n",
    "3. 목적대로 train 되었는지 testset으로 확인 -- Freeze된 ResNet으로 classification을 잘 수행하는가..  \n",
    "    3.1 ResNet은 아무런 train이 필요 없나? 뭔갈 해야하나? \n",
    "4. train 잘 되었다면 그 담에 뭘 할까? -- M20, Gini, Contrast등의 값을 feature vector로 변경. --> custom_morph 코드를 Train된 ResNet으로 변경. \n",
    "\n",
    "ToneMapping이 바뀔 때마다 ResNet의 마지막 layer 정도는 fine-tune할 수 있지 않을까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ceb4ec-02bf-400f-a04e-7a278523eb46",
   "metadata": {},
   "source": [
    "# n_channel option added\n",
    "\n",
    "models: torchvision.models -> atm.simclr.resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc69a9d-55e7-40e5-8829-b7664c0c2c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "#from torchvision import models\n",
    "\n",
    "\n",
    "import atm\n",
    "import atm.simclr as simclr\n",
    "import atm.simclr.resnet as models\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "import argparse \n",
    "\n",
    "\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.n_channel = 1\n",
    "\n",
    "args.data='./datasets' \n",
    "args.dataset_name='cifar10'\n",
    "args.arch='resnet50'\n",
    "args.workers=1\n",
    "args.epochs=300 \n",
    "args.batch_size=256 \n",
    "args.lr=3e-4\n",
    "args.weight_decay=1e-4\n",
    "args.disable_cuda=False\n",
    "args.fp16_precision=True\n",
    "args.out_dim=10\n",
    "args.log_every_n_steps=100\n",
    "args.temperature=0.07\n",
    "args.n_views = 2\n",
    "args.gpu_index=0\n",
    "args.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args.device = 'cpu'\n",
    "print(\"Using device:\", args.device)\n",
    "\n",
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    args.gpu_index = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f896ac44-2ab2-4550-8150-689e26ecd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from torchvision import transforms, datasets\n",
    "#from exceptions.exceptions import InvalidDatasetSelection\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"blur a single image on CPU\"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        radias = kernel_size // 2\n",
    "        kernel_size = radias * 2 + 1\n",
    "        self.blur_h = nn.Conv2d(3, 3, kernel_size=(kernel_size, 1),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.blur_v = nn.Conv2d(3, 3, kernel_size=(1, kernel_size),\n",
    "                                stride=1, padding=0, bias=False, groups=3)\n",
    "        self.k = kernel_size\n",
    "        self.r = radias\n",
    "\n",
    "        self.blur = nn.Sequential(\n",
    "            nn.ReflectionPad2d(radias),\n",
    "            self.blur_h,\n",
    "            self.blur_v\n",
    "        )\n",
    "\n",
    "        self.pil_to_tensor = transforms.ToTensor()\n",
    "        self.tensor_to_pil = transforms.ToPILImage()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = self.pil_to_tensor(img).unsqueeze(0)\n",
    "\n",
    "        sigma = np.random.uniform(0.1, 2.0)\n",
    "        x = np.arange(-self.r, self.r + 1)\n",
    "        x = np.exp(-np.power(x, 2) / (2 * sigma * sigma))\n",
    "        x = x / x.sum()\n",
    "        x = torch.from_numpy(x).view(1, -1).repeat(3, 1)\n",
    "\n",
    "        self.blur_h.weight.data.copy_(x.view(3, 1, self.k, 1))\n",
    "        self.blur_v.weight.data.copy_(x.view(3, 1, 1, self.k))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            img = self.blur(img)\n",
    "            img = img.squeeze()\n",
    "\n",
    "        img = self.tensor_to_pil(img)\n",
    "\n",
    "        return img\n",
    "\n",
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transform(x) for i in range(self.n_views)]\n",
    "    \n",
    "class ContrastiveLearningDataset:\n",
    "    def __init__(self, root_folder):\n",
    "        self.root_folder = root_folder\n",
    "\n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size, s=1, n_channels=3):\n",
    "        \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "        _transform = [transforms.RandomResizedCrop(size=size),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.RandomApply([color_jitter], p=0.8),\n",
    "                      transforms.RandomGrayscale(p=0.2),\n",
    "                      GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                      transforms.ToTensor()]\n",
    "        if n_channels == 1:\n",
    "            _transform = _transform + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "            \n",
    "        data_transforms = transforms.Compose(_transform)\n",
    "        #print(\"get_simclr_pipeline_transform\", data_transforms, \"n_channels=\", n_channels)\n",
    "        return data_transforms\n",
    "\n",
    "    def get_dataset(self, name, n_views, n_channels=3):\n",
    "        #print(\"get_dataset\", n_channels)\n",
    "        valid_datasets = {'cifar10': lambda: datasets.CIFAR10(self.root_folder, train=True,\n",
    "                                                              transform=ContrastiveLearningViewGenerator(\n",
    "                                                                  self.get_simclr_pipeline_transform(32, n_channels=n_channels),\n",
    "                                                                  n_views),\n",
    "                                                              download=True),\n",
    "\n",
    "                          'stl10': lambda: datasets.STL10(self.root_folder, split='unlabeled',\n",
    "                                                          transform=ContrastiveLearningViewGenerator(\n",
    "                                                              self.get_simclr_pipeline_transform(96, n_channels=n_channels),\n",
    "                                                              n_views),\n",
    "                                                          download=True)}\n",
    "\n",
    "        try:\n",
    "            dataset_fn = valid_datasets[name]\n",
    "        except KeyError:\n",
    "            raise #InvalidDatasetSelection()\n",
    "        else:\n",
    "            return dataset_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecec212e-826a-43b5-80db-c42bcb7b9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetSimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super(ResNetSimCLR, self).__init__()\n",
    "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim),\n",
    "                            \"resnet50\": models.resnet50(pretrained=False, num_classes=out_dim)}\n",
    "\n",
    "        self.backbone = self._get_basemodel(base_model)\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "\n",
    "        # add mlp projection head\n",
    "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
    "\n",
    "    def _get_basemodel(self, model_name):\n",
    "        try:\n",
    "            model = self.resnet_dict[model_name]\n",
    "        except KeyError:\n",
    "            raise InvalidBackboneError(\n",
    "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
    "        else:\n",
    "            return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "670217fd-0a05-4ba5-8d31-e6760c577aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "#from utils import save_config_file, accuracy, save_checkpoint\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def save_config_file(model_checkpoints_folder, args):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
    "            yaml.dump(args, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "class SimCLR(object):\n",
    "    \"\"\"\n",
    "    presumably irrelevant to channel count.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = kwargs['args']\n",
    "        self.model = kwargs['model'].to(self.args.device)\n",
    "        self.optimizer = kwargs['optimizer']\n",
    "        self.scheduler = kwargs['scheduler']\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {self.args.disable_cuda}.\")\n",
    "\n",
    "        for epoch_counter in range(self.args.epochs):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % self.args.log_every_n_steps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "                n_iter += 1\n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'n_channel':self.args.n_channel,\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c0fc632-4966-43ba-bd0c-ca63ac4e5e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "#args = parser.parse_args()\n",
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    args.gpu_index = -1\n",
    "\n",
    "dataset = ContrastiveLearningDataset(args.data)\n",
    "\n",
    "train_dataset = dataset.get_dataset(args.dataset_name, args.n_views, n_channels=args.n_channel)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "model = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                       last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e11d75a1-1b2c-4061-8ddb-3a1f556279be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2646ebf5-6396-42bd-8f35-1604ff13b968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 1, 32, 32])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d40af5f-69eb-48dc-a3bd-de92730d95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/amp/autocast_mode.py:120: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n",
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:508: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      " 43%|████▎     | 84/195 [02:08<02:50,  1.53s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-45538287f6b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msimclr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msimclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-5637d7b88232>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  It’s a no-op if the 'gpu_index' argument is a negative integer or None.\n",
    "with torch.cuda.device(args.gpu_index):\n",
    "    simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simclr.train(train_loader)\n",
    "        \n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4de9e6-d383-4ceb-8453-4e5b9f89ad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d5f45-202a-45fa-a6bf-2a9c5dd86340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ee4fde-e80b-47ba-b142-25bace1e75a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 22/195 [00:08<01:04,  2.67it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c4002e8d79a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for images, _ in tqdm(train_loader):\n",
    "    images = torch.cat(images, dim=0)\n",
    "\n",
    "    images = images.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aaec39e-89d4-4588-9e8a-2fe77aedbb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 3, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669fa50-a7b9-4e78-8fba-c1291672c874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
