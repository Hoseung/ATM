{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2cfb668-72e4-4b92-b576-3c609c8ba3f9",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/a-complete-guide-to-using-tensorboard-with-pytorch-53cb2301e8c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96fb91e3-f2ae-4663-8009-7a08188b33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "torch.set_printoptions(linewidth=120)\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571fa0d4-4f6c-4e05-81ec-6b5646ad5e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111e110-9816-43f7-af95-0c9e1c2ce527",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860f131-8a7c-45ad-a2bb-79411e269f8c",
   "metadata": {},
   "source": [
    "# Tensorboard SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be10025-1097-4aa4-926b-e778f9538f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755ae46b-cd2e-479a-8267-7cd43ad865c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "# sum of predics equal to labels when preds == argmax of class probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710fb69c-108c-4cd9-bbc7-91aa41a301b4",
   "metadata": {},
   "source": [
    "## Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1ac9e4-739e-4f60-aec7-da5084cc9bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9c50e61-15d7-4ea8-8cf6-8a32f9c50285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f8527dc27b4e56bf311abed7bc1910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c5d947259e4603a58141292d39c138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468f0ea0d60c4d689d0979db7457d5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb6c1754333470d90c439662907f797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torchvision/datasets/mnist.py:335: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554782469/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  return torch.from_numpy(parsed).view(length, num_rows, num_cols)\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(root=\"./data\",\n",
    "train = True,\n",
    " download=True,\n",
    "transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fedde60-ba1d-45fc-b961-7f86a9477b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = SummaryWriter() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d082f-d1ad-4c69-9472-6cbbc18e915a",
   "metadata": {},
   "source": [
    "SummaryWriter(log_dir) creates log_dir to store log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fe9d8f-a337-45d1-b85d-42812d0772e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\"\n",
    "model = CNN()\n",
    "images, labels = next(iter(train_loader))\n",
    "grid = torchvision.utils.make_grid(images)\n",
    "tb.add_image(\"images\", grid)\n",
    "tb.add_graph(model, images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225f3d7-5d9f-4193-95e4-176dbcc0b024",
   "metadata": {},
   "source": [
    "# Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e103d7-517d-45ae-b769-e9d16f0d4d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 48173 loss: 318.929568991065\n",
      "epoch: 1 total_correct: 51843 loss: 220.7587616443634\n",
      "epoch: 2 total_correct: 52521 loss: 202.61319528520107\n",
      "epoch: 3 total_correct: 52843 loss: 194.4499491006136\n",
      "epoch: 4 total_correct: 52984 loss: 190.95944210886955\n",
      "epoch: 5 total_correct: 53149 loss: 185.70717848092318\n",
      "epoch: 6 total_correct: 53244 loss: 182.6273631080985\n",
      "epoch: 7 total_correct: 53524 loss: 177.43566562235355\n",
      "epoch: 8 total_correct: 53423 loss: 178.32259202748537\n",
      "epoch: 9 total_correct: 53680 loss: 173.0257710069418\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else cpu)\n",
    "model = CNN().to(device)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size = 100, shuffle = True)\n",
    "optimizer = opt.Adam(model.parameters(), lr= 0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "\n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss+= loss.item()\n",
    "        total_correct+= get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct/ len(train_set), epoch)\n",
    "\n",
    "    tb.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
    "    tb.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
    "    tb.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
    "    tb.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb3bff-37ca-4c0b-8684-44a154a3f6ae",
   "metadata": {},
   "source": [
    "# Monitoring Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5222c0c5-f29f-42c4-85eb-ae180b2bf7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "parameters = dict(lr = [0.01, 0.001],\n",
    "                  batch_szie=[32,64,128],\n",
    "                  shuffle = [True, False])\n",
    "param_values = [v for v in parameters.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7edbcbdf-734c-4d4a-8ab9-4f402227b773",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id 1\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 47802 loss: 1023.2121961787343\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 50385 loss: 810.8808999881148\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 50992 loss: 777.6378016620874\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 51422 loss: 750.2654168866575\n",
      "batch_size: 32 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 51558 loss: 728.7547300029546\n",
      "__________________________________________________________\n",
      "run id 2\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 46353 loss: 1128.91398049891\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 49656 loss: 891.4816038459539\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 50110 loss: 858.0037266984582\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 50267 loss: 844.4450650215149\n",
      "batch_size: 32 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 50277 loss: 844.1931204646826\n",
      "__________________________________________________________\n",
      "run id 3\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 47956 loss: 505.9296161234379\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51369 loss: 368.1062406376004\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 51873 loss: 346.8910147473216\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 52112 loss: 336.0628538802266\n",
      "batch_size: 64 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 52452 loss: 322.4006816968322\n",
      "__________________________________________________________\n",
      "run id 4\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 46900 loss: 540.747764468193\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 50999 loss: 382.7199611067772\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 51493 loss: 358.7730498313904\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 51830 loss: 348.411694586277\n",
      "batch_size: 64 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 52009 loss: 341.3338393867016\n",
      "__________________________________________________________\n",
      "run id 5\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 0 total_correct: 46652 loss: 272.348208129406\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 1 total_correct: 51511 loss: 180.82077997922897\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 2 total_correct: 52213 loss: 164.39001704752445\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 3 total_correct: 52725 loss: 153.92360535264015\n",
      "batch_size: 128 lr: 0.01 shuffle: True\n",
      "epoch: 4 total_correct: 53066 loss: 146.9708161354065\n",
      "__________________________________________________________\n",
      "run id 6\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 0 total_correct: 46149 loss: 282.8351982831955\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 1 total_correct: 51016 loss: 188.6147761940956\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 2 total_correct: 51872 loss: 169.27520827949047\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 3 total_correct: 52242 loss: 162.3807687908411\n",
      "batch_size: 128 lr: 0.01 shuffle: False\n",
      "epoch: 4 total_correct: 52385 loss: 157.7757239639759\n",
      "__________________________________________________________\n",
      "run id 7\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 44846 loss: 1252.0096426606178\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 50545 loss: 806.8918441236019\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 51950 loss: 687.9833310768008\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 52621 loss: 626.6174340620637\n",
      "batch_size: 32 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 53028 loss: 586.073090155609\n",
      "__________________________________________________________\n",
      "run id 8\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 45356 loss: 1205.0516148358583\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 50674 loss: 795.826513454318\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 51895 loss: 685.2493747286499\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 52609 loss: 622.1660447046161\n",
      "batch_size: 32 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 53075 loss: 578.4842339381576\n",
      "__________________________________________________________\n",
      "run id 9\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 42905 loss: 696.4519181549549\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 49083 loss: 459.35646256804466\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 50665 loss: 398.180545091629\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 51542 loss: 361.3021247088909\n",
      "batch_size: 64 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 52109 loss: 334.4067367911339\n",
      "__________________________________________________________\n",
      "run id 10\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 43230 loss: 688.2542652189732\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 49169 loss: 453.8464256078005\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 50905 loss: 389.58216811716557\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 51781 loss: 350.6992177516222\n",
      "batch_size: 64 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 52404 loss: 325.35197626799345\n",
      "__________________________________________________________\n",
      "run id 11\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 0 total_correct: 41184 loss: 388.5899921953678\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 1 total_correct: 47605 loss: 252.0353443324566\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 2 total_correct: 49967 loss: 213.51250275969505\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 3 total_correct: 51019 loss: 190.72186017036438\n",
      "batch_size: 128 lr: 0.001 shuffle: True\n",
      "epoch: 4 total_correct: 51847 loss: 175.14323137700558\n",
      "__________________________________________________________\n",
      "run id 12\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 0 total_correct: 40905 loss: 389.97935461997986\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 1 total_correct: 47985 loss: 250.3175406754017\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 2 total_correct: 49967 loss: 217.36332780122757\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 3 total_correct: 50962 loss: 197.19763205945492\n",
      "batch_size: 128 lr: 0.001 shuffle: False\n",
      "epoch: 4 total_correct: 51551 loss: 183.15809333324432\n",
      "__________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for run_id, (lr, batch_size, shuffle) in enumerate(product(*param_values)):\n",
    "    print(\"run id\", run_id+1)\n",
    "    model = CNN().to(device)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=shuffle)\n",
    "    optimizer = opt.Adam(model.parameters(), lr=lr)\n",
    "    criterion=torch.nn.CrossEntropyLoss()\n",
    "    comment = f'batch_size = {batch_size} lr = {lr} shuffle = {shuffle}'\n",
    "    tb = SummaryWriter(comment=comment)\n",
    "    for epoch in range(5):\n",
    "        total_loss = 0\n",
    "        total_correct = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            preds = model(images)\n",
    "            \n",
    "            loss = criterion(preds, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += get_num_correct(preds, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "        tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "        tb.add_scalar(\"Accuracy\", total_correct / len(train_set), epoch)\n",
    "        \n",
    "        print(\"batch_size:\",batch_size, \"lr:\",lr,\"shuffle:\",shuffle)\n",
    "        print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\",total_loss)\n",
    "    print(\"__________________________________________________________\")\n",
    "\n",
    "    tb.add_hparams(\n",
    "            {\"lr\": lr, \"bsize\": batch_size, \"shuffle\":shuffle},\n",
    "            {\n",
    "                \"accuracy\": total_correct/ len(train_set),\n",
    "                \"loss\": total_loss,\n",
    "            },\n",
    "        )\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c7e49-f480-4214-bdb8-7b4d781851d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
