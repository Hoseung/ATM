{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72b92497-778f-4664-892f-4c906672f47c",
   "metadata": {},
   "source": [
    "Restart cuda module after suspend by:  \n",
    "`$ sudo rmmod nvidia_uvm`  \n",
    "`$ sudo modprobe nvidia_uvm`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29714ca-50dc-46b9-b5e9-8ce7d6e19049",
   "metadata": {},
   "source": [
    "1. Test용으로 몇 장 빼둘 것. \n",
    "2. Train의 목적: -- T-type을 N개의 label로 잘 구별하는 representation vector를 구하는 것.  \n",
    "3. 목적대로 train 되었는지 testset으로 확인 -- Freeze된 ResNet으로 classification을 잘 수행하는가..  \n",
    "    3.1 ResNet은 아무런 train이 필요 없나? 뭔갈 해야하나? \n",
    "4. train 잘 되었다면 그 담에 뭘 할까? -- M20, Gini, Contrast등의 값을 feature vector로 변경. --> custom_morph 코드를 Train된 ResNet으로 변경. \n",
    "\n",
    "ToneMapping이 바뀔 때마다 ResNet의 마지막 layer 정도는 fine-tune할 수 있지 않을까? \n",
    "\n",
    "\n",
    "\n",
    "Gaussian blur는 1-channel에도 적용할 수 있을 것 같은데."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d7b449-d861-42d0-b884-666fc34d5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "#from torchvision import models\n",
    "\n",
    "import atm\n",
    "import atm.simclr as simclr\n",
    "import atm.simclr.resnet as models\n",
    "\n",
    "import argparse \n",
    "\n",
    "from PIL import Image\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from functools import partial\n",
    "from astrobf.tmo import Mantiuk_Seidel\n",
    "\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "#from utils import save_config_file, accuracy, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901210b-4ca3-4d54-aa9f-2689b106ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_parallel = True\n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.data='./datasets' \n",
    "#args.dataset_name='cifar10'\n",
    "args.arch='resnet50'\n",
    "args.workers=1\n",
    "args.epochs=300 \n",
    "\n",
    "if do_parallel:\n",
    "    args.batch_size = 128\n",
    "else:\n",
    "    args.batch_size = 256\n",
    "\n",
    "args.lr=0.02\n",
    "args.weight_decay=0.0005\n",
    "args.disable_cuda=False\n",
    "args.fp16_precision=True\n",
    "args.out_dim=10\n",
    "args.log_every_n_steps=100\n",
    "args.temperature=0.07\n",
    "args.n_views = 2\n",
    "#args.gpu_index=0\n",
    "args.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using device:\", args.device)\n",
    "\n",
    "img_size =128\n",
    "\n",
    "\n",
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    #args.gpu_index = -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transform(x) for i in range(self.n_views)]\n",
    "    \n",
    "class TonemapImageDataset(VisionDataset):\n",
    "    def __init__(self, \n",
    "                 data_array, \n",
    "                 tmo,\n",
    "                 labels: Optional = None, \n",
    "                 train: bool=True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,):\n",
    "        self._array = data_array\n",
    "        self._good_gids = np.array([gal['img_name'] for gal in data_array])\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.tmo = tmo\n",
    "        self._bad_tmo=False\n",
    "\n",
    "    def _apply_tm(self, image):\n",
    "        try:\n",
    "            return self.tmo(image)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"division by zero. Probably bad choice of TM parameters\")\n",
    "            self._bad_tmo=True\n",
    "            return image\n",
    "\n",
    "    def _to_8bit(self, image):\n",
    "        \"\"\"\n",
    "        Normalize per image (or use global min max??)\n",
    "        \"\"\"\n",
    "\n",
    "        image = (image - image.min())/image.ptp()\n",
    "        image *= 255\n",
    "        return image.astype('uint8')        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._array)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        For super\n",
    "        \"\"\"\n",
    "        image, _segmap, weight = self._array[idx]['data']\n",
    "        image[~_segmap.astype(bool)] = 0#np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "\n",
    "        image = self._to_8bit(self._apply_tm(image))\n",
    "        image = Image.fromarray(image)\n",
    "        target = self.img_labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        return image, target\n",
    "\n",
    "    \n",
    "class ContrastiveLearningDataset():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size, s=1, n_channels=3):\n",
    "        \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                              transforms.RandomGrayscale(p=0.2),\n",
    "                                              GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                                              transforms.ToTensor()])\n",
    "        if n_channels == 1:\n",
    "            _transform = _transform + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "            \n",
    "        return data_transforms\n",
    "\n",
    "    def get_dataset(self, name, n_views, n_channels=3):\n",
    "        return TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                labels=cat['TT'].to_numpy(),\n",
    "                                train=True, \n",
    "                                transform=ContrastiveLearningViewGenerator(\n",
    "                                    self.get_simclr_pipeline_transform(img_size, n_channels=1)\n",
    "                                ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ddir = \"../../tonemap/bf_data/Nair_and_Abraham_2010/\"\n",
    "\n",
    "fn = ddir + \"all_gals.pickle\"\n",
    "all_gals = pickle.load(open(fn, \"rb\"))\n",
    "\n",
    "all_gals = all_gals[1:] # Why the first galaxy image is NaN?\n",
    "\n",
    "good_gids = np.array([gal['img_name'] for gal in all_gals])\n",
    "\n",
    "from astrobf.utils.misc import load_Nair\n",
    "cat_data = load_Nair(ddir + \"catalog/table2.dat\")\n",
    "# pd dataframe\n",
    "\n",
    "cat = cat_data[cat_data['ID'].isin(good_gids)]\n",
    "\n",
    "tmo_params = {'b': 6.0,  'c': 3.96, 'dl': 9.22, 'dh': 2.45}\n",
    "\n",
    "\n",
    "\n",
    "class ResNetSimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super(ResNetSimCLR, self).__init__()\n",
    "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim, num_channels=1),\n",
    "                            \"resnet50\": models.resnet50(pretrained=False, num_classes=out_dim, num_channels=1)}\n",
    "\n",
    "        self.backbone = self._get_basemodel(base_model)\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "\n",
    "        # add mlp projection head\n",
    "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
    "\n",
    "    def _get_basemodel(self, model_name):\n",
    "        try:\n",
    "            model = self.resnet_dict[model_name]\n",
    "        except KeyError:\n",
    "            raise InvalidBackboneError(\n",
    "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
    "        else:\n",
    "            return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def save_config_file(model_checkpoints_folder, args):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
    "            yaml.dump(args, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "class SimCLR(object):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = kwargs['args']\n",
    "        self.model = kwargs['model'].to(self.args.device)\n",
    "        self.optimizer = kwargs['optimizer']\n",
    "        self.scheduler = kwargs['scheduler']\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {self.args.disable_cuda}.\")\n",
    "\n",
    "        for epoch_counter in range(self.args.epochs):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % self.args.log_every_n_steps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "                n_iter += 1\n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "            'batchsize': self.args.batch_size,\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")\n",
    "\n",
    "\n",
    "def get_simclr_pipeline_transform(size, s=1, n_channels=3):\n",
    "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "    #color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "    _transforms = [transforms.RandomResizedCrop(size=size),\n",
    "                  transforms.RandomHorizontalFlip(),\n",
    "                  #transforms.RandomApply([color_jitter], p=0.8), <- 3 channel이어야만 사용 가능\n",
    "                  #transforms.RandomGrayscale(p=0.2),\n",
    "                  #GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                  transforms.ToTensor()]\n",
    "    if n_channels == 1:\n",
    "        _transforms = _transforms + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "\n",
    "    return transforms.Compose(_transforms)\n",
    "\n",
    "train_dataset = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                    labels=cat['TT'].to_numpy(),\n",
    "                                    train=True, \n",
    "                                    transform=ContrastiveLearningViewGenerator(\n",
    "                                        get_simclr_pipeline_transform(128, n_channels=1)\n",
    "                                    ))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "model = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "if do_parallel:\n",
    "    model = nn.DataParallel(model)#, output_device=1) # split works into different devices. 1 deals with the output, 0 does the rest.\n",
    "    # The commented part causes an error:\n",
    "    # Expected all tensors to be on the same device, but found at least two devices,\n",
    "    # cuda:1 and cuda:0! (when checking arugment for argument target in method wrapper_nll_loss_forward)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                       last_epoch=-1)\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore')\n",
    "#  It’s a no-op if the 'gpu_index' argument is a negative integer or None.\n",
    "#with torch.cuda.device(args.gpu_index):\n",
    "simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "simclr.train(train_loader)\n",
    "        \n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb118301-a403-4e1d-8dfd-898226b8632c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37f20f-01c2-47b6-a5de-fac2ad006427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdf5a1-fc77-4974-b235-0a64b0468682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac1229-6e35-4a48-b01d-32797bc51d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fe1980-1337-4c86-8058-79e7c65bdc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9185c0-19e3-40d6-ac45-47d6e1c45f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f7b1d-296f-445d-808e-f7b541c8f605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f04c8-b48d-4e5e-9024-71468c2d2b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45130772-fec9-42e4-9c98-2d5708361627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b590e0-0baa-4756-b7d1-9d1c746af556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88feaf-cdb7-4e25-80e9-4e20de0a0ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dae43d-7589-48e4-a410-8ec37d4291c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687c770-bc68-4efe-8205-b17cbf9f352e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb13103f-c7c2-4535-af7d-6f6b75b66930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "#from torchvision import models\n",
    "\n",
    "import atm\n",
    "import atm.simclr as simclr\n",
    "import atm.simclr.resnet as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e425938e-ef50-46b9-9fac-aee1b751f37a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataSet\n",
    "\n",
    "Dataset yields a pair of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224625a8-de37-4edb-aa21-b49794f18a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/cuda/CUDAFunctions.cpp:115.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import argparse \n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.data='./datasets' \n",
    "#args.dataset_name='cifar10'\n",
    "args.arch='resnet50'\n",
    "args.workers=1\n",
    "args.epochs=300 \n",
    "args.batch_size=32\n",
    "args.lr=0.02\n",
    "args.weight_decay=0.0005\n",
    "args.disable_cuda=False\n",
    "args.fp16_precision=True\n",
    "args.out_dim=10\n",
    "args.log_every_n_steps=100\n",
    "args.temperature=0.07\n",
    "args.n_views = 2\n",
    "args.gpu_index=0\n",
    "args.device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(\"Using device:\", args.device)\n",
    "\n",
    "img_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4a1036-3af8-4b40-9326-f560cdfad33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    args.gpu_index = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f12c6-9529-4f01-a739-3612934790f2",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0718dca2-c4dc-4945-b963-9d6a5b7ba1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from functools import partial\n",
    "from astrobf.tmo import Mantiuk_Seidel\n",
    "\n",
    "\n",
    "class ContrastiveLearningViewGenerator(object):\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform, n_views=2):\n",
    "        self.base_transform = base_transform\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return [self.base_transform(x) for i in range(self.n_views)]\n",
    "    \n",
    "class TonemapImageDataset(VisionDataset):\n",
    "    def __init__(self, \n",
    "                 data_array, \n",
    "                 tmo,\n",
    "                 labels: Optional = None, \n",
    "                 train: bool=True,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 target_transform: Optional[Callable] = None,):\n",
    "        self._array = data_array\n",
    "        self._good_gids = np.array([gal['img_name'] for gal in data_array])\n",
    "        self.img_labels = labels\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.tmo = tmo\n",
    "        self._bad_tmo=False\n",
    "\n",
    "    def _apply_tm(self, image):\n",
    "        try:\n",
    "            return self.tmo(image)\n",
    "        except ZeroDivisionError:\n",
    "            print(\"division by zero. Probably bad choice of TM parameters\")\n",
    "            self._bad_tmo=True\n",
    "            return image\n",
    "\n",
    "    def _to_8bit(self, image):\n",
    "        \"\"\"\n",
    "        Normalize per image (or use global min max??)\n",
    "        \"\"\"\n",
    "\n",
    "        image = (image - image.min())/image.ptp()\n",
    "        image *= 255\n",
    "        return image.astype('uint8')        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._array)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        For super\n",
    "        \"\"\"\n",
    "        image, _segmap, weight = self._array[idx]['data']\n",
    "        image[~_segmap.astype(bool)] = 0#np.nan # Is it OK to have nan?\n",
    "        image[image < 0] = 0\n",
    "\n",
    "        image = self._to_8bit(self._apply_tm(image))\n",
    "        image = Image.fromarray(image)\n",
    "        target = self.img_labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "            \n",
    "        return image, target\n",
    "\n",
    "    \n",
    "class ContrastiveLearningDataset():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_simclr_pipeline_transform(size, s=1, n_channels=3):\n",
    "        \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "        color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "        data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                              transforms.RandomGrayscale(p=0.2),\n",
    "                                              GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                                              transforms.ToTensor()])\n",
    "        if n_channels == 1:\n",
    "            _transform = _transform + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "            \n",
    "        return data_transforms\n",
    "\n",
    "    def get_dataset(self, name, n_views, n_channels=3):\n",
    "        return TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                labels=cat['TT'].to_numpy(),\n",
    "                                train=True, \n",
    "                                transform=ContrastiveLearningViewGenerator(\n",
    "                                    self.get_simclr_pipeline_transform(128, n_channels=1)\n",
    "                                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6421ccf-3c7b-4950-8043-c183bfa105b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "ddir = \"../../tonemap/bf_data/Nair_and_Abraham_2010/\"\n",
    "\n",
    "fn = ddir + \"all_gals.pickle\"\n",
    "all_gals = pickle.load(open(fn, \"rb\"))\n",
    "\n",
    "all_gals = all_gals[1:] # Why the first galaxy image is NaN?\n",
    "\n",
    "good_gids = np.array([gal['img_name'] for gal in all_gals])\n",
    "\n",
    "from astrobf.utils.misc import load_Nair\n",
    "cat_data = load_Nair(ddir + \"catalog/table2.dat\")\n",
    "# pd dataframe\n",
    "\n",
    "cat = cat_data[cat_data['ID'].isin(good_gids)]\n",
    "\n",
    "tmo_params = {'b': 6.0,  'c': 3.96, 'dl': 9.22, 'dh': 2.45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92883037-5ec4-4849-b41c-0eca3f6f8fad",
   "metadata": {},
   "source": [
    "## distribution of original image sizes \n",
    "\n",
    "생각보다 크다.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fabe109-e94a-498b-9c6f-8a7f1d3cf865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_sizes = []\n",
    "for gg in all_gals:\n",
    "    mm, _, _ = gg['data']\n",
    "    img_sizes.append(mm.shape[0])\n",
    "\n",
    "plt.hist(img_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b760c29-b5fd-4838-9603-fe29595c8649",
   "metadata": {},
   "source": [
    "EFIGI 은하에 대해서 테스트 하는건 어떰? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41810cb2-aa30-4cf9-b44c-138a9f709079",
   "metadata": {},
   "source": [
    "RandomCrop을 할 의미가 있을까?\n",
    "은하의 중심이 어느정도 결정되어있고, 일부를 봐야하는 상황은 없으며, radial한 pattern이 중요한데. \n",
    "거기다가 은하별로 크기가 많이 차이나서 잘못하면 텅텅 빈 공간을 잘라오는 수가 있음. \n",
    "\n",
    "Rotation이랑 flip 정도만 말이 됨.\n",
    "\n",
    "\n",
    "은하 말고 다른HDR 이미지에 톤맵해서 돌아가나 테스트해보기.\n",
    "\n",
    "JPEG/PNG으로 한번 저장을 해보고, 바로 loading하는 경우랑 sanity check. Model마다 loader를 새로 쓰기는 귀찮으니. bnechmarking때 쓸모있을 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1712935-8f5b-417b-aa97-ba871ee7f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_for_png = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                labels=cat['TT'].to_numpy(),\n",
    "                                train=False, \n",
    "                                transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d434490-df7d-4759-bd65-ecb5639a3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "484c4b6c-2125-4bf6-b024-238bdf9f11ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = \"../../tonemap/bf_data/ImageDataset/Nair/\"\n",
    "if not os.path.isdir(ddir):\n",
    "        os.mkdir(ddir)\n",
    "        \n",
    "for (im, _), cc in zip(all_for_png, cat.iterrows()):\n",
    "    gid, tt, area = cc[1]['ID'], cc[1]['TT'], cc[1]['area']\n",
    "    this_dir = ddir + f\"{tt}/\"\n",
    "    if not os.path.isdir(this_dir):\n",
    "        os.mkdir(this_dir)\n",
    "    \n",
    "    im.save(this_dir+f'{gid}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9a27ec9-3f99-4810-ba21-c4a0029d158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID      J235929.61p161009.65\n",
       "TT                        -5\n",
       "area                  347.54\n",
       "Name: 3209, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35db0e70-8d84-4673-8572-3bd36c22995a",
   "metadata": {},
   "source": [
    "TT를 표준화해야하나? \n",
    "ID를 저장할 필요가 있을까? index를 다시 붙일까."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb0e936-1408-430e-aa2d-582afab6a3c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b56425-4fdd-441e-bcfa-5fc84c189389",
   "metadata": {},
   "source": [
    "s = 1\n",
    "color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "data_transforms = transforms.Compose([transforms.RandomResizedCrop(size=img_size),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                      transforms.RandomGrayscale(p=0.2),\n",
    "                                      GaussianBlur(kernel_size=int(0.1 * img_size)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))])\n",
    "#if n_channels == 1:\n",
    "#    _transform = _transform + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29078c1c-3e74-4ecb-ab6e-1f989169691b",
   "metadata": {},
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    #transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8), \n",
    "    #transforms.RandomGrayscale(p=0.2), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.2])])#[0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])]) \n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.2])])#0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4006a-2ced-4dcc-b1f9-f8190891faa7",
   "metadata": {},
   "source": [
    "## Split one chunk of dataset into train and test\n",
    "#### Use torch.utils.data.random_split or [torch.utils.data.SubsetRandomSampler](https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets/50544887#50544887)\n",
    "\n",
    "random_split takes a dataset -- for example, a tuple (tensor of data, tensor of label).  \n",
    "SubsetRandomSampler is sent to a DataLoader as an optional argument. SubsetRandomSampler better suits to my case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a6ce2f-24b0-420b-8b19-b21fcc338192",
   "metadata": {},
   "source": [
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "args.batch_size = 512\n",
    "# data prepare\n",
    "frac_train = 0.8\n",
    "\n",
    "all_data = TonemapImageDatasetPair(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                     labels=cat['TT'].to_numpy(),\n",
    "                                     train=True, \n",
    "                                     transform=train_transform)\n",
    "\n",
    "all_data_val = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                     labels=cat['TT'].to_numpy(),\n",
    "                                     train=False, \n",
    "                                     transform=test_transform)\n",
    "len_data = len(all_data)\n",
    "\n",
    "data_idx = np.arange(len_data)\n",
    "np.random.shuffle(data_idx)\n",
    "ind = int(np.floor(len_data * frac_train))\n",
    "train_idx, test_idx = data_idx[:ind], data_idx[ind:]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = DataLoader(all_data, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True, drop_last=True,\n",
    "                         sampler=train_sampler)\n",
    "\n",
    "test_loader = DataLoader(all_data_val, batch_size=args.batch_size, shuffle=False, num_workers=16, pin_memory=True, drop_last=True,\n",
    "                         sampler=test_sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5a0c89-4c1b-4f5a-a919-7ec91887fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetSimCLR(nn.Module):\n",
    "\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super(ResNetSimCLR, self).__init__()\n",
    "        self.resnet_dict = {\"resnet18\": models.resnet18(pretrained=False, num_classes=out_dim, num_channels=1),\n",
    "                            \"resnet50\": models.resnet50(pretrained=False, num_classes=out_dim, num_channels=1)}\n",
    "\n",
    "        self.backbone = self._get_basemodel(base_model)\n",
    "        dim_mlp = self.backbone.fc.in_features\n",
    "\n",
    "        # add mlp projection head\n",
    "        self.backbone.fc = nn.Sequential(nn.Linear(dim_mlp, dim_mlp), nn.ReLU(), self.backbone.fc)\n",
    "\n",
    "    def _get_basemodel(self, model_name):\n",
    "        try:\n",
    "            model = self.resnet_dict[model_name]\n",
    "        except KeyError:\n",
    "            raise InvalidBackboneError(\n",
    "                \"Invalid backbone architecture. Check the config file and pass one of: resnet18 or resnet50\")\n",
    "        else:\n",
    "            return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66512e49-d943-4c78-90cf-4a14b35346ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "#from utils import save_config_file, accuracy, save_checkpoint\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def save_config_file(model_checkpoints_folder, args):\n",
    "    if not os.path.exists(model_checkpoints_folder):\n",
    "        os.makedirs(model_checkpoints_folder)\n",
    "        with open(os.path.join(model_checkpoints_folder, 'config.yml'), 'w') as outfile:\n",
    "            yaml.dump(args, outfile, default_flow_style=False)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "class SimCLR(object):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = kwargs['args']\n",
    "        self.model = kwargs['model'].to(self.args.device)\n",
    "        self.optimizer = kwargs['optimizer']\n",
    "        self.scheduler = kwargs['scheduler']\n",
    "        self.writer = SummaryWriter()\n",
    "        logging.basicConfig(filename=os.path.join(self.writer.log_dir, 'training.log'), level=logging.DEBUG)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.device)\n",
    "\n",
    "    def info_nce_loss(self, features):\n",
    "\n",
    "        labels = torch.cat([torch.arange(self.args.batch_size) for i in range(self.args.n_views)], dim=0)\n",
    "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "        labels = labels.to(self.args.device)\n",
    "\n",
    "        features = F.normalize(features, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(features, features.T)\n",
    "        # assert similarity_matrix.shape == (\n",
    "        #     self.args.n_views * self.args.batch_size, self.args.n_views * self.args.batch_size)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # discard the main diagonal from both: labels and similarities matrix\n",
    "        mask = torch.eye(labels.shape[0], dtype=torch.bool).to(self.args.device)\n",
    "        labels = labels[~mask].view(labels.shape[0], -1)\n",
    "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "        # assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "        # select and combine multiple positives\n",
    "        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "        # select only the negatives the negatives\n",
    "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "        logits = torch.cat([positives, negatives], dim=1)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.args.device)\n",
    "\n",
    "        logits = logits / self.args.temperature\n",
    "        return logits, labels\n",
    "\n",
    "    def train(self, train_loader):\n",
    "\n",
    "        scaler = GradScaler(enabled=self.args.fp16_precision)\n",
    "\n",
    "        # save config file\n",
    "        save_config_file(self.writer.log_dir, self.args)\n",
    "\n",
    "        n_iter = 0\n",
    "        logging.info(f\"Start SimCLR training for {self.args.epochs} epochs.\")\n",
    "        logging.info(f\"Training with gpu: {self.args.disable_cuda}.\")\n",
    "\n",
    "        for epoch_counter in range(self.args.epochs):\n",
    "            for images, _ in tqdm(train_loader):\n",
    "                images = torch.cat(images, dim=0)\n",
    "\n",
    "                images = images.to(self.args.device)\n",
    "\n",
    "                with autocast(enabled=self.args.fp16_precision):\n",
    "                    features = self.model(images)\n",
    "                    logits, labels = self.info_nce_loss(features)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "                if n_iter % self.args.log_every_n_steps == 0:\n",
    "                    top1, top5 = accuracy(logits, labels, topk=(1, 5))\n",
    "                    self.writer.add_scalar('loss', loss, global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top1', top1[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('acc/top5', top5[0], global_step=n_iter)\n",
    "                    self.writer.add_scalar('learning_rate', self.scheduler.get_lr()[0], global_step=n_iter)\n",
    "\n",
    "                n_iter += 1\n",
    "\n",
    "            # warmup for the first 10 epochs\n",
    "            if epoch_counter >= 10:\n",
    "                self.scheduler.step()\n",
    "            logging.debug(f\"Epoch: {epoch_counter}\\tLoss: {loss}\\tTop1 accuracy: {top1[0]}\")\n",
    "\n",
    "        logging.info(\"Training has finished.\")\n",
    "        # save model checkpoints\n",
    "        checkpoint_name = 'checkpoint_{:04d}.pth.tar'.format(self.args.epochs)\n",
    "        save_checkpoint({\n",
    "            'epoch': self.args.epochs,\n",
    "            'arch': self.args.arch,\n",
    "            'state_dict': self.model.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }, is_best=False, filename=os.path.join(self.writer.log_dir, checkpoint_name))\n",
    "        logging.info(f\"Model checkpoint and metadata has been saved at {self.writer.log_dir}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b72f6de8-205d-4f48-b181-37bc9dadbbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:508: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "100%|██████████| 298/298 [00:18<00:00, 16.43it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.95it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.94it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.92it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.94it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.93it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.92it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.95it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.95it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.92it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.89it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.95it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.90it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.72it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.93it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.87it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.95it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.88it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.92it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.81it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.85it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.79it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.84it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.89it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.88it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.93it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.85it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.88it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.86it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.95it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.89it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.84it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.88it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.89it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.90it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.91it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.89it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.90it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.89it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.92it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.90it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.11it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.12it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.11it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.96it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.97it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.11it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.13it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.12it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.11it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.11it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.12it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.01it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.04it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.06it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.09it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.99it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 16.98it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.10it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.07it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.00it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.05it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.08it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.03it/s]\n",
      "  0%|          | 0/298 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "100%|██████████| 298/298 [00:17<00:00, 17.02it/s]\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "#args = parser.parse_args()\n",
    "assert args.n_views == 2, \"Only two view training is supported. Please use --n-views 2.\"\n",
    "# check if gpu training is available\n",
    "if not args.disable_cuda and torch.cuda.is_available():\n",
    "    args.device = torch.device('cuda')\n",
    "    cudnn.deterministic = True\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    args.device = torch.device('cpu')\n",
    "    args.gpu_index = -1\n",
    "\n",
    "#dataset = ContrastiveLearningDataset(args.data)\n",
    "#train_dataset = dataset.get_dataset(args.dataset_name, args.n_views)\n",
    "def get_simclr_pipeline_transform(size, s=1, n_channels=3):\n",
    "    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\n",
    "    #color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "    _transforms = [transforms.RandomResizedCrop(size=size),\n",
    "                  transforms.RandomHorizontalFlip(),\n",
    "                  #transforms.RandomApply([color_jitter], p=0.8), <- 3 channel이어야만 사용 가능\n",
    "                  #transforms.RandomGrayscale(p=0.2),\n",
    "                  #GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                  transforms.ToTensor()]\n",
    "    if n_channels == 1:\n",
    "        _transforms = _transforms + [transforms.Lambda(lambda x: x.mean(dim=0, keepdim=True))]\n",
    "\n",
    "    return transforms.Compose(_transforms)\n",
    "\n",
    "train_dataset = TonemapImageDataset(all_gals, partial(Mantiuk_Seidel, **tmo_params),\n",
    "                                    labels=cat['TT'].to_numpy(),\n",
    "                                    train=True, \n",
    "                                    transform=ContrastiveLearningViewGenerator(\n",
    "                                        get_simclr_pipeline_transform(128, n_channels=1)\n",
    "                                    ))\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
    "    num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "\n",
    "model = ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                       last_epoch=-1)\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore')\n",
    "#  It’s a no-op if the 'gpu_index' argument is a negative integer or None.\n",
    "with torch.cuda.device(args.gpu_index):\n",
    "    simclr = SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simclr.train(train_loader)\n",
    "        \n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec5b55a6-0d8c-4ba2-b50d-adc80a180891",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetSimCLR(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b64728-d58c-4395-846b-21714a1863b3",
   "metadata": {},
   "source": [
    "## Q \n",
    "shuflle = False is forced because \"sampler option is mutually exclusive with shuffle\".  \n",
    "Do I get different batches in different epochs? I want to train on different set of contrastive examples...   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e362b2b8-c679-4306-ba72-84a89a922074",
   "metadata": {},
   "source": [
    "## quick check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b515341-db59-4d28-abb5-c85249d4e8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37 [00:00<?, ?it/s]/home/hoseung/Work/tonemap/astroBF/astrobf/tmo.py:268: RuntimeWarning: divide by zero encountered in log10\n",
      "  lp = np.log10(lum) # L prime\n",
      "  0%|          | 0/37 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-15-84df8faba3c0>\", line 67, in __getitem__\n    image = self.transform(image)\n  File \"<ipython-input-15-84df8faba3c0>\", line 16, in __call__\n    return [self.base_transform(x) for i in range(self.n_views)]\n  File \"<ipython-input-15-84df8faba3c0>\", line 16, in <listcomp>\n    return [self.base_transform(x) for i in range(self.n_views)]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torchvision/transforms/transforms.py\", line 60, in __call__\n    img = t(img)\n  File \"<ipython-input-7-4d808040457a>\", line 39, in __call__\n    img = self.blur(img)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 119, in forward\n    input = module(input)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 399, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 395, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: Given groups=3, weight of size [3, 1, 13, 1], expected input[1, 1, 140, 140] to have 3 channels, but got 1 channels instead\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-40286d4f30a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfeature_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#images = images.to(args.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-15-84df8faba3c0>\", line 67, in __getitem__\n    image = self.transform(image)\n  File \"<ipython-input-15-84df8faba3c0>\", line 16, in __call__\n    return [self.base_transform(x) for i in range(self.n_views)]\n  File \"<ipython-input-15-84df8faba3c0>\", line 16, in <listcomp>\n    return [self.base_transform(x) for i in range(self.n_views)]\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torchvision/transforms/transforms.py\", line 60, in __call__\n    img = t(img)\n  File \"<ipython-input-7-4d808040457a>\", line 39, in __call__\n    img = self.blur(img)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 119, in forward\n    input = module(input)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 399, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/home/hoseung/anaconda3/envs/tm39/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 395, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\nRuntimeError: Given groups=3, weight of size [3, 1, 13, 1], expected input[1, 1, 140, 140] to have 3 channels, but got 1 channels instead\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "feature_arr = []\n",
    "for images, _ in tqdm(train_loader):\n",
    "    images = torch.cat(images, dim=0)\n",
    "    #images = images.to(args.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a39ed0-b2d4-4b53-ab40-d72d6861fe48",
   "metadata": {},
   "source": [
    "center를 shift하지는 않는게 좋겠음. \n",
    "\n",
    "Batch size: 한 epoch에서 충분한 정보를 얻을 수 있어야 앞으로 나갈 수 있음. 얼만큼이 충분한지는 미리 알 방법이 없음. c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e996e768-bc91-4f44-8ffe-238f1ae6811a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(4,4)\n",
    "axs = axs.ravel()\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.imshow(images[i][0])\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a318a21-06d2-480a-a210-51e1e8d52cc2",
   "metadata": {},
   "source": [
    "원래 예제 (CIPAR10)의 image 값 범위를 확인해볼 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a5a60b-b883-4eac-8269-36ebbe9ae171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean tensor(-1.4847) max tensor(2.4412) min tensor(-2.5000)\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\", images[1].mean(), \"max\", images[1].max(), \"min\", images[1].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44edf816-1c1b-4410-b040-01ce5de01ba9",
   "metadata": {},
   "source": [
    "#### Input 이미지는 문제 없어보임. 근데 왜 첫 loss 부터 nan이 나오는가? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e167c1-230c-48c2-a714-2e1f8f323cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'atm.simclr.models' from '/home/hoseung/Work/ATM/atm/simclr/models.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(simclr)\n",
    "importlib.reload(simclr.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c9fdee-0172-46cd-ac58-8b842248b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simclr.models.ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr, weight_decay=args.wd)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(train_loader), eta_min=0,\n",
    "                                                           last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c732e565-1060-4fdd-8e2b-7601bab9d477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116cadef-7f57-4db1-8c49-c17dc4ac048b",
   "metadata": {},
   "source": [
    "특정 배치에 있었던 이미지를 보려면?\n",
    "\n",
    "loss는 쬐끔 줄어드려던 중이었음. weight가 explode한 듯? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac266149-2ea4-4bc5-bf3c-b746fc2a68ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]/home/hoseung/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  0%|          | 0/14 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.77 GiB total capacity; 9.45 GiB already allocated; 210.00 MiB free; 9.67 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1f6e625af057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msimc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msimc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model is saved at the end of train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Work/ATM/atm/simclr/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;31m# autocast <- AMP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16_precision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                     \u001b[0;31m################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_nce_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/ATM/atm/simclr/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2281\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.77 GiB total capacity; 9.45 GiB already allocated; 210.00 MiB free; 9.67 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "np.seterr(divide='ignore')\n",
    "\n",
    "with torch.cuda.device(args.gpu_index):\n",
    "    simc = simclr.models.SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simc.train(train_loader) # model is saved at the end of train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d14f370b-0c79-4ef4-a3af-e7037422167e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -0.614746 0.624023\n",
      "current loss tensor(6.9046, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:01<00:16,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -0.616699 0.629883\n",
      "current loss tensor(6.8819, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:01<00:08,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -0.631348 0.643555\n",
      "current loss tensor(6.9004, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:01<00:06,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -0.615723 0.62793\n",
      "current loss tensor(6.9031, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [00:02<00:04,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -0.619629 0.630371\n",
      "current loss tensor(6.8663, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [00:02<00:03,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -0.621582 0.633301\n",
      "current loss tensor(6.8742, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [00:02<00:03,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -59.2188 52.4375\n",
      "current loss tensor(6.9910, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [00:03<00:02,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -526.0 498.0\n",
      "current loss tensor(6.8321, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -1271.0 1211.0\n",
      "current loss tensor(6.7893, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [00:04<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -2080.0 1982.0\n",
      "current loss tensor(6.7055, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -2794.0 2654.0\n",
      "current loss tensor(6.7217, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [00:04<00:01,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -3388.0 3212.0\n",
      "current loss tensor(6.6837, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [00:05<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -4020.0 3810.0\n",
      "current loss tensor(6.5888, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -4368.0 4152.0\n",
      "current loss tensor(6.5025, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:05<00:00,  2.37it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/14 [00:01<00:16,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 2/14 [00:01<00:08,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -4660.0 4428.0\n",
      "current loss tensor(6.5194, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 3/14 [00:01<00:06,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 4/14 [00:02<00:04,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5/14 [00:02<00:03,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 6/14 [00:02<00:03,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 7/14 [00:03<00:02,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 8/14 [00:03<00:02,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 9/14 [00:04<00:01,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 10/14 [00:04<00:01,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 11/14 [00:04<00:01,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 12/14 [00:05<00:00,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature min max -inf inf\n",
      "current loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 13/14 [00:05<00:00,  2.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1f6e625af057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msimc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimCLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msimc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# model is saved at the end of train.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Work/ATM/atm/simclr/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m                 \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.seterr(divide='ignore')\n",
    "\n",
    "with torch.cuda.device(args.gpu_index):\n",
    "    simc = simclr.models.SimCLR(model=model, optimizer=optimizer, scheduler=scheduler, args=args)\n",
    "    simc.train(train_loader) # model is saved at the end of train."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f2dd1-83f3-4f86-95c9-66a67b46d59b",
   "metadata": {},
   "source": [
    "# representation quality check\n",
    "\n",
    "## linear evaluation protocol, a standard way\n",
    "Train a linear classifier on the fixed representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cd287d-2ce8-49be-a900-1efe37dc13e0",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f863a7c-b316-40e3-a40a-f78bf9bbc1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    checkpoint = torch.load('./runs/Aug23_00-13-48_hoseung/checkpoint_0300.pth.tar', map_location=args.device)\n",
    "    state_dict = checkpoint['state_dict']\n",
    "    \n",
    "    resnet = simclr.models.ResNetSimCLR(base_model=args.arch, out_dim=args.out_dim)\n",
    "    resnet.to(args.device)\n",
    "    log = resnet.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    print(log)\n",
    "else:\n",
    "    resnet = simc.model\n",
    "    print(\"Using live simc instance\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b44696-26ce-4c84-acee-e6f5a37bea7f",
   "metadata": {},
   "source": [
    "### Discard the projection head and leave the original backbone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcfe77ee-dcac-4a9c-8758-60b3c4168776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the projection head\n",
    "resnet.backbone.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa4249-c6fb-4ccc-a6b8-b2d95c805195",
   "metadata": {},
   "source": [
    "## t_SNE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eba302-b71b-4083-8692-cb92e51bd35d",
   "metadata": {},
   "source": [
    "### Get features of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6896d-91a1-4ec0-b09d-55063abb0ec6",
   "metadata": {},
   "source": [
    "test_transform에서 to_tensor해줬는데...??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d888a4-ca57-4b38-b2ce-1fe7b683cd9a",
   "metadata": {},
   "source": [
    "### Test set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c815686d-6b9b-4f4a-9278-43721198acff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast\n",
    "feature_arr = []\n",
    "for images, _ in tqdm(test_loader):\n",
    "    #images = torch.cat(images, dim=0)\n",
    "    images = images.to(args.device)\n",
    "\n",
    "    # autocast <- AMP\n",
    "    with autocast(enabled=args.fp16_precision):\n",
    "        features = resnet.backbone(images)\n",
    "        \n",
    "    feature_arr.append(features.cpu().detach().numpy())\n",
    "\n",
    "feature_arr = np.concatenate(feature_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f133de35-fd01-4cb0-8adb-eb8e477e2bf3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.backbone.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68678e77-72e0-4536-b970-17b4686be72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = resnet.backbone.layer4[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e9eb5812-dd74-40b5-a9d5-13400f9281d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (downsample): Sequential(\n",
       "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c890b7e-cd4d-4484-a33e-3bf4c5cd0f81",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]]],\n",
       "\n",
       "\n",
       "        [[[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]]],\n",
       "\n",
       "\n",
       "        [[[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]]],\n",
       "\n",
       "\n",
       "        [[[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]]],\n",
       "\n",
       "\n",
       "        [[[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]],\n",
       "\n",
       "         [[nan]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5f64b-19fe-421f-bdbd-4849c65b869e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734e28c-7f36-414b-b61c-f2f2c4a5f5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791fb49-e771-45f7-ad44-d5e6a0b3e2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da7283a4-2ce0-4029-9339-f453d4f415da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f7757ed-0d2b-4b65-afdf-56e18d80d1b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-20fdbe62efb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtsne_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \"\"\"\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    700\u001b[0m             )\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'barnes_hut'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             X = self._validate_data(X, accept_sparse=['csr'],\n\u001b[0m\u001b[1;32m    703\u001b[0m                                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                                     dtype=[np.float32, np.float64])\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(feature_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab07201-3304-4332-b546-71971c577146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81bc6be-f43e-42bd-b6ba-6d8405e4ee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D projection of 1024(?)-dim features\n",
    "tsne = TSNE(n_components=2).fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f72538-0511-44be-a23b-07ae38c733f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(resnet.parameters(), lr=3e-4, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(args.device)\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3688320-95d0-4530-9912-b1fd240be9a9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b100bbc-4cc5-46bd-b87f-fecd9f177571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "    train_dataset = torchvision.datasets.CIFAR10('./data', train=True, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=0, drop_last=False, shuffle=shuffle)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10('./data', train=False, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=shuffle)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
    "# num_workers=0. Using multiple (even num_workers=1) causes an error 'can only test a child process'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f7892c-858b-4537-9feb-e5d5a3edccf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "995934b9-9aac-4611-920a-38ddfd4dddbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-d3c238119daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tm39/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    top1_train_accuracy = 0\n",
    "    for counter, (x_batch,y_batch) in enumerate(train_loader):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        y_batch = y_batch.to(args.device)\n",
    "        \n",
    "        logits = resnet(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "        top1_train_accuracy += top1[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    top1_train_accuracy /= (counter + 1)\n",
    "    top1_accuracy = 0\n",
    "    top5_accuracy = 0\n",
    "    for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        y_batch = y_batch.to(args.device)\n",
    "\n",
    "        logits = resnet(x_batch)\n",
    "\n",
    "        top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "        top1_accuracy += top1[0]\n",
    "        top5_accuracy += top5[0]\n",
    "\n",
    "    top1_accuracy /= (counter + 1)\n",
    "    top5_accuracy /= (counter + 1)\n",
    "    print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c547670-5db7-444a-bf75-a9ab1c28a3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f0fd7-cd2a-48ea-a509-2d91c60f1e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35a883-dc56-439c-a5d5-dd4cec870c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimCLRClassifier(nn.Module):\n",
    "    def __init__(self, base_model, freeze_base, base_feature_size=512, n_views=2):\n",
    "        self.embeddings = base_model\n",
    "        \n",
    "        if freeze_base:\n",
    "            print(\"Freezing embeddings\")\n",
    "            for param in self.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.classifier = nn.Linear(in_features = base_feature_size, \n",
    "                                   out_features = n_views) #\n",
    "    \n",
    "    def forward(self, X, *args):\n",
    "        emb = self.embeddings(X)\n",
    "        return self.classifier(emb)\n",
    "    \n",
    "class SimCLRClassifierModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b98fb7d-5412-4a0b-99da-e178b5fc7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44972a0b-3eb2-497b-a23c-654373fc8ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader, module):\n",
    "    with torch.no_grad():\n",
    "        progress = [\"/\", \"-\", \"\\\\\", \"|\", \"/\", \"-\", \"\\\\\", \"|\"]\n",
    "        module.eval().cuda()\n",
    "        true_y, pred_y = [], []\n",
    "        for i, batch_ in enumerate(data_loader):\n",
    "            X, y = batch_\n",
    "            print(progress[i % len(progress)], end=\"\\r\")\n",
    "            y_pred = torch.argmax(module(X.cuda()), dim=1)\n",
    "            true_y.extend(y.cpu())\n",
    "            pred_y.extend(y_pred.cpu())\n",
    "        print(classification_report(true_y, pred_y, digits=3))\n",
    "        return true_y, pred_y\n",
    "\n",
    "_ = evaluate(module.val_dataloader(), module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
