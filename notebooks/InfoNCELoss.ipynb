{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf910f72-eed6-498b-bd47-30dbb719e685",
   "metadata": {},
   "source": [
    "왜 contrastive learning이 generative, predictive learning보다 더 좋은 representation을 학습하는가? \n",
    "\n",
    "-> loss를 정의하는 space가 다름... 음 좀 더 자세히... \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4f9797-54b0-4caf-bb09-e6a53c8671cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3213761e-696f-431a-8ff1-035de5f961c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse \n",
    "\n",
    "args = argparse.Namespace()\n",
    "\n",
    "args.data='./datasets' \n",
    "args.dataset_name='cifar10'\n",
    "args.n_views = 2\n",
    "args.workers=1\n",
    "args.arch='resnet50'\n",
    "args.out_dim=128\n",
    "args.wd=0.0005\n",
    "args.batch_size=256\n",
    "args.device='cuda'\n",
    "args.temperature=0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe878bec-1f15-4647-a4c7-026324b789f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d113a19-f4d6-4b0c-9840-8f14123f9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.rand(2*args.batch_size,2048) # mimic ResNet50 embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ff289c-929e-42b7-8f6e-b126f96f9f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2861)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f9578e6-2eb8-4ac1-87f7-2e90676a6df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "         10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,\n",
      "         24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,\n",
      "         38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "         80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,\n",
      "         94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
      "        108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
      "        122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
      "        136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,\n",
      "        150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
      "        164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
      "        178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191,\n",
      "        192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
      "        206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n",
      "        220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "        248, 249, 250, 251, 252, 253, 254, 255])\n"
     ]
    }
   ],
   "source": [
    "labels = torch.cat([torch.arange(args.batch_size) for i in range(args.n_views)], dim=0) \n",
    "# 2 x batch size, simply index array x2\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4416cc-c36e-4092-8141-ca13495f0fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93db8c78-d362-4959-8e38-f031fddc1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.to(args.device)\n",
    "\n",
    "features = F.normalize(features, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c99e56a-6076-4870-980e-616a0cf03ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0385)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "333d3eb7-b427-41cd-a8f7-b1b205623a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.5212, 10.0602,  9.7840,  ...,  9.7557, 10.0513,  9.5111])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10214922-b664-4b04-8473-b6e6c88f1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = torch.matmul(features, features.T)\n",
    "# assert similarity_matrix.shape == (\n",
    "#     args.n_views * args.batch_size, args.n_views * args.batch_size)\n",
    "# assert similarity_matrix.shape == labels.shape\n",
    "\n",
    "# discard the main diagonal from both: labels and similarities matrix\n",
    "mask = torch.eye(labels.shape[0], dtype=torch.bool).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a29a233e-514b-4f8a-96fd-ab1d9ac912f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[~mask].view(labels.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9387a318-c9eb-45cb-9682-d478c543415e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 511])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b51491d7-bfb4-4501-a3a3-1d4839dd868b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.7547, 0.7486,  ..., 0.7443, 0.7488, 0.7517],\n",
       "        [0.7547, 1.0000, 0.7499,  ..., 0.7497, 0.7597, 0.7498],\n",
       "        [0.7486, 0.7499, 1.0000,  ..., 0.7553, 0.7439, 0.7462],\n",
       "        ...,\n",
       "        [0.7443, 0.7497, 0.7553,  ..., 1.0000, 0.7463, 0.7432],\n",
       "        [0.7488, 0.7597, 0.7439,  ..., 0.7463, 1.0000, 0.7543],\n",
       "        [0.7517, 0.7498, 0.7462,  ..., 0.7432, 0.7543, 1.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61a0f56a-e630-406d-8bcc-43438a13e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
    "# assert similarity_matrix.shape == labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e1a8f4d-0424-459e-bf67-5c3989579281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512])\n"
     ]
    }
   ],
   "source": [
    "# select and combine multiple positives\n",
    "positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n",
    "\n",
    "# select only the negatives the negatives\n",
    "negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
    "\n",
    "logits = torch.cat([positives, negatives], dim=1)\n",
    "labels = torch.zeros(logits.shape[0], dtype=torch.long).to(args.device)\n",
    "\n",
    "logits = logits / args.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15831c9a-87d9-4b8b-b233-54b89066de44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 511])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b907cdac-a5c4-4c1f-8171-215e0df9a8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
